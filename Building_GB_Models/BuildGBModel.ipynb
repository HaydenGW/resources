{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Gradient Boosting Models\n",
    "\n",
    "Clone the repo at:\n",
    "www.github.com/numeristical/resources\n",
    "\n",
    "Navigate to folder: \"Building_GB_Models\"\n",
    "\n",
    "Open the notebook file: \"BuildGBModel.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, log_loss, r2_score\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import hyperopt as hp\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ames Housing Data\n",
    "\n",
    "We'll use the Ames housing data.  This is a small-ish (<3K) size data set of houses sold in Ames, Iowa from 2006 to 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_house = pd.read_csv('../GBIP/data/Ames_Housing_Data.tsv', delimiter='\\t')\n",
    "df_house = df_house.loc[df_house['Gr Liv Area']<=4000,:]\n",
    "df_house['Garage Area'].fillna(0, inplace=True)\n",
    "df_house.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are lots of features here...\n",
    "df_house.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's focus on a smaller subset of features...\n",
    "feat_1 = ['Lot Area','Overall Qual',\n",
    "       'Overall Cond', 'Year Built', 'Year Remod/Add', 'Gr Liv Area', \n",
    "        'Full Bath', 'Half Bath', 'Bedroom AbvGr',\n",
    "         'Garage Area', 'Fireplaces']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_house.iloc[:,:-1]  # everything except Sale Price\n",
    "y = df_house.SalePrice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X,y,test_size = 400, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:,feat_1].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building Process\n",
    "- ### Explore and interrogate your data\n",
    "- ### Start with a simple baseline model\n",
    "- ### Use early stopping, tune `max_depth` first\n",
    "- ### Check where your model is doing poorly\n",
    "- ### Try to engineer features to address model shortcomings\n",
    "    - #### Use domain expertise / common knowledge\n",
    "- ### Save \"big\" hyperparameter tuning until the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore and interrogate the data\n",
    "- Look at data before modeling!\n",
    "    - Understand the distribution of the target variable (and know its mean).\n",
    "    - Explore relationships between the target and the features\n",
    "    - Look for \"idiosyncracies\" or other artifacts in your data\n",
    "    - Try to understand what different values \"mean\"\n",
    "    - Sometimes variables have deeper meanings....\n",
    "<br>\n",
    "- For regression problems, the `pairplot` in the seaborn package is a nice way to look at all of the bivariate relationships.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean of your target variable\n",
    "np.mean(df_house.SalePrice), np.min(df_house.SalePrice), np.max(df_house.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a histogram - doesn't look great at first\n",
    "plt.hist(df_house.SalePrice);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Redo the histogram with \"nicer\" bins\n",
    "binpts = np.linspace(0,700000, 70+1)\n",
    "plt.hist(df_house.SalePrice, bins=binpts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a pairplot - this may take a minute or two to complete\n",
    "sns.pairplot(df_house.loc[:,feat_1+['SalePrice']], plot_kws={'alpha':.1});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "- What variables seem to have the strongest relationship with the SalePrice?\n",
    "- What is going on with 'Year Built' and 'Year Remod/Add'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lot Area is hard to see due to outliers - let's plot it again here\n",
    "plt.scatter(df_house['Lot Area'], df_house['SalePrice'], alpha=.1)\n",
    "plt.xlim([0,30000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with a simple baseline model\n",
    "- Often people start modeling by assembling all the relevant features, trying automated feature selection and massive grid searches to get the best model.\n",
    "- This typically results in a model with lots of features that are basically irrelevant.\n",
    "- It is costly to have lots of features in your model!\n",
    "    - Every feature is a potential failure point\n",
    "- In most cases, can get most of the performance from relatively few features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_0 = ['Lot Area',\n",
    " 'Overall Qual',\n",
    " 'Year Built',\n",
    " 'Gr Liv Area',\n",
    " 'Bedroom AbvGr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data sets of just the smaller subset of features\n",
    "X_train_0 = X_train_full.loc[:, feat_0]\n",
    "X_test_0 = X_test_full.loc[:, feat_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create / train Random Forest on just 5 variables\n",
    "rf0 = RandomForestRegressor(n_estimators=1000, n_jobs=-1)\n",
    "rf0.fit(X_train_0, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf0 = rf0.predict(X_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RMSE and MAE of the predictions\n",
    "np.sqrt(mean_squared_error(y_test, preds_rf0)), mean_absolute_error(y_test, preds_rf0), r2_score(y_test, preds_rf0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted (y) vs actual (x)\n",
    "plt.scatter(x=y_test, y=preds_rf0, alpha=.2, marker='.')\n",
    "plt.plot([0,500000],[0,500000], 'k--')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a baseline of performance, we can make sure that the additional complexities (more features, GB instead of RF, etc.) are actually improving things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try the 11 feature model and see how much it improves our random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data sets of the set of 11 features\n",
    "X_train_1 = X_train_full.loc[:, feat_1]\n",
    "X_test_1 = X_test_full.loc[:, feat_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create / train Random Forest on 11 variables\n",
    "rf1 = RandomForestRegressor(n_estimators=1000, n_jobs=-1)\n",
    "rf1.fit(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf1 = rf1.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RMSE and MAE of the 11-feature RF predictions\n",
    "np.sqrt(mean_squared_error(y_test, preds_rf1)), mean_absolute_error(y_test, preds_rf1), r2_score(y_test, preds_rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare to previous predictions\n",
    "np.sqrt(mean_squared_error(y_test, preds_rf0)), mean_absolute_error(y_test, preds_rf0), r2_score(y_test, preds_rf0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_rf1))/np.sqrt(mean_squared_error(y_test, preds_rf0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a substantial improvement.  \n",
    "- R2 from 87.3 -> 90.2.  \n",
    "- 12% drop in RMSE\n",
    "\n",
    "So we can feel confident the additional 6 variables are adding predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted (y) vs actual (x)\n",
    "plt.scatter(y_test, preds_rf1, alpha=.2, marker='.')\n",
    "plt.plot([0,500000],[0,500000], 'k--')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model Building\n",
    "Now that we have a baseline to compare against, we can begin modeling with Gradient Boosting.  Having a baseline will help us determine the quality of our hyperparameter settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "For now, we will use the XGBoost package for Gradient Boosting.  XGBoost first came out in 2015.  The acronym is \"eXtreme Gradient Boosting\".  It implemented a number of theoretical and practical improvements, many of which have become standard in subsequent packages:\n",
    "\n",
    "- *Native handling of missing data*: (Missing values are checked to see if they \"fit\" better on the left or right side of the tree for each split values)\n",
    "- *Newton steps*: rather than just finding the gradient, XGBoost also looks at the second derivative to determine the step size.\n",
    "- *Advanced Regularization*: XGBoost rederived the math to flexibly incorporate *shrinkage* (similar to Lasso/Ridge Regression) and penalize the number of splits.\n",
    "- *Not checking every split*: XGBoost had a method for deriving quantiles to avoid checking every split (particularly in large datasets when a predictor has a large number of possible values).  Though not the default, this has since been shown to be effective both for speeding up the training *and* as another source of regularization\n",
    "- *Distributed training*: XGBoost had implementations for working with large datasets that are not held in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's use an XGBoost model with default parameters\n",
    "xgb_def = xgb.XGBRegressor()\n",
    "xgb_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_def.fit(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb_def = xgb_def.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_xgb_def)), mean_absolute_error(y_test, preds_xgb_def), r2_score(y_test, preds_xgb_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Baseline 11-feature RF predictions\n",
    "np.sqrt(mean_squared_error(y_test, preds_rf1)), mean_absolute_error(y_test, preds_rf1), r2_score(y_test, preds_rf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that we actually do **worse** than the Random Forest model when we use the default parameter settings.\n",
    "- It is very difficult to get the number of trees / learning rate right without early stopping!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Early Stopping!!\n",
    "\n",
    "As we just saw, using the default parameters on gradient boosting can easily give you results that are not very good.  Here, it does worse than a simple Random Forest\n",
    "\n",
    "However, this does NOT mean you need to do massive grid searches to get good results\n",
    "\n",
    "As discussed in the Fundamentals of Gradient Boosting course:\n",
    "\n",
    "- The three most important parameters in your boosting model are the *max_depth*, *learning_rate*, and *n_estimators*.  \n",
    "- Setting these is made more challenging by the fact that they are highly interactive\n",
    "- The best way to handle this is:\n",
    "    - Set aside a validation set for early stopping\n",
    "    - Use a low-ish `learning rate`\n",
    "    - Use a high `n_estimators` (we will early stop)\n",
    "    - Stop when performance on the validation set begins to degrade\n",
    "    \n",
    "XGBoost (like most other boosting packages) makes it easy to implement early stopping, as we demonstrate below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a big number of trees, and a small learning rate\n",
    "# We will not actually fit so many trees, since the early stopping will kick in\n",
    "xgb1 = xgb.XGBRegressor(n_estimators=5000, learning_rate=.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add trees until we show no improvement (i.e. no new low) for 10 trees\n",
    "xgb1.fit(X_train_1, y_train, \n",
    "         eval_set=[(X_test_1, y_test)], \n",
    "        early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb1 = xgb1.predict(X_test_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_xgb1)), mean_absolute_error(y_test, preds_xgb1), r2_score(y_test, preds_xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compared to last model\n",
    "np.sqrt(mean_squared_error(y_test, preds_xgb_def)), mean_absolute_error(y_test, preds_xgb_def), r2_score(y_test, preds_xgb_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Baseline 11-feature RF predictions\n",
    "np.sqrt(mean_squared_error(y_test, preds_rf1)), mean_absolute_error(y_test, preds_rf1), r2_score(y_test, preds_rf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With early stopping we get a significant improvement over the default GB model and a slight improvement over the baseline RF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's tune the max depth\n",
    "\n",
    "md_vals_vec=list(range(1,10))\n",
    "rmse_vec = np.zeros(len(md_vals_vec))\n",
    "for i,md in enumerate(md_vals_vec):\n",
    "    print(f'Training with max_depth {md}')\n",
    "    xgb_temp = xgb.XGBRegressor(max_depth=md, \n",
    "                        n_estimators=5000, learning_rate=.01, \n",
    "         early_stopping_rounds = 10) #, early_stopping_rounds=10)\n",
    "    xgb_temp.fit(X_train_1, y_train, \n",
    "         eval_set=[(X_test_1, y_test)], \n",
    "                 verbose=0)\n",
    "    preds = xgb_temp.predict(X_test_1)\n",
    "    rmse_vec[i] = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "## Note - for newer versions of xgboost, this might scream at you....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance vs. max_depth\n",
    "plt.plot(md_vals_vec, rmse_vec, marker='x')\n",
    "np.min(rmse_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best `max_depth` is at 3, let's try re-training at that max_depth value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = xgb.XGBRegressor(max_depth=3, n_estimators=5000, learning_rate=.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add trees until we show no improvement (i.e. no new low) for 10 trees\n",
    "xgb2.fit(X_train_1, y_train, \n",
    "         eval_set=[(X_test_1, y_test)], \n",
    "        early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb2 = xgb2.predict(X_test_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_xgb2)), mean_absolute_error(y_test, preds_xgb2), r2_score(y_test, preds_xgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compared to previous model (un-tuned max_depth)\n",
    "np.sqrt(mean_squared_error(y_test, preds_xgb1)), mean_absolute_error(y_test, preds_xgb1), r2_score(y_test, preds_xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_xgb2))/np.sqrt(mean_squared_error(y_test, preds_xgb1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a significant improvement in RMSE from tuning the `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating and Improving the Model\n",
    "Note that we are already iterating and improving our model!\n",
    "<br>\n",
    "We are following a cycle:\n",
    "- Fit model\n",
    "- Make predictions\n",
    "- Evaluate the quality of our predictions\n",
    "- Compare to previous models\n",
    "- Make adjustments and repeat the cycle\n",
    "\n",
    "However, thus far, we have just made simple \"no-brainer\" improvements - going from RF to GB, implementing early-stopping, tuning the max_depth.\n",
    "\n",
    "Now, we start using our brains, our domain expertise to make further improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure Analysis\n",
    "A great way to look for improvements is to examine the cases where the model made its biggest mistakes.\n",
    "\n",
    "- Look at cases where the model performed poorly\n",
    "- Try to understand why the model's prediction was so different from reality\n",
    "- See if there is anything in the data that would reflect this reasoning\n",
    "- Try to adjust model, add / engineer features to capture this useful information\n",
    "- Rerun model and see if it improves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We calculate the residuals - discrepancies between true answer and prediction\n",
    "# Positive residual => model underpredicted true value\n",
    "# Negative residual => model overpredicted true value\n",
    "resids = (y_test - preds_xgb2)\n",
    "abs_resids = np.abs(resids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(resids, bins = np.linspace(-100000,100000,101));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_val_test = X_test_full.loc[resids>30000]\n",
    "under_val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "over_val_test = X_test_full.loc[resids<-30000]\n",
    "over_val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_3 = ['Lot Area','Overall Qual',\n",
    "       'Overall Cond', 'Year Built', 'Year Remod/Add', 'Gr Liv Area', \n",
    "        'Full Bath', 'Half Bath', 'Bedroom AbvGr',\n",
    "         'Garage Area', 'Fireplaces', 'BsmtFin SF 1']#, 'BsmtFin SF 2']\n",
    "\n",
    "X_train_3 = X_train_full.loc[:, feat_3]\n",
    "X_test_3 = X_test_full.loc[:, feat_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = xgb.XGBRegressor(max_depth=3, n_estimators=5000, learning_rate=.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add trees until we show no improvement (i.e. no new low) for 10 trees\n",
    "xgb3.fit(X_train_3, y_train, \n",
    "         eval_set=[(X_test_3, y_test)], \n",
    "        early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb3 = xgb3.predict(X_test_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_xgb3)), mean_absolute_error(y_test, preds_xgb3), r2_score(y_test, preds_xgb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_xgb2)), mean_absolute_error(y_test, preds_xgb2), r2_score(y_test, preds_xgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_3a = ['Lot Area','Overall Qual',\n",
    "       'Overall Cond', 'Year Built', 'Year Remod/Add', 'Gr Liv Area', \n",
    "        'Full Bath', 'Half Bath', 'Bedroom AbvGr',\n",
    "         'Garage Area', 'Fireplaces', 'BsmtFin SF 1', 'BsmtFin SF 2']\n",
    "\n",
    "X_train_3a = X_train_full.loc[:, feat_3a]\n",
    "X_test_3a = X_test_full.loc[:, feat_3a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3a = xgb.XGBRegressor(max_depth=3, n_estimators=5000, learning_rate=.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add trees until we show no improvement (i.e. no new low) for 10 trees\n",
    "xgb3a.fit(X_train_3a, y_train, \n",
    "         eval_set=[(X_test_3a, y_test)], \n",
    "        early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb3a = xgb3a.predict(X_test_3a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_xgb3a)), mean_absolute_error(y_test, preds_xgb3a), r2_score(y_test, preds_xgb3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_xgb3)), mean_absolute_error(y_test, preds_xgb3), r2_score(y_test, preds_xgb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_full['BsmtFinSFtotal'] = X_train_full['BsmtFin SF 1']+X_train_full['BsmtFin SF 2']\n",
    "X_test_full['BsmtFinSFtotal'] = X_test_full['BsmtFin SF 1']+X_test_full['BsmtFin SF 2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_4 = ['Lot Area','Overall Qual',\n",
    "       'Overall Cond', 'Year Built', 'Year Remod/Add', 'Gr Liv Area', \n",
    "        'Full Bath', 'Half Bath', 'Bedroom AbvGr',\n",
    "         'Garage Area', 'Fireplaces', 'BsmtFinSFtotal']\n",
    "\n",
    "X_train_4 = X_train_full.loc[:, feat_4]\n",
    "X_test_4 = X_test_full.loc[:, feat_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb4 = xgb.XGBRegressor(max_depth=3, n_estimators=5000, learning_rate=.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add trees until we show no improvement (i.e. no new low) for 10 trees\n",
    "xgb4.fit(X_train_4, y_train, \n",
    "         eval_set=[(X_test_4, y_test)], \n",
    "        early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_xgb4 = xgb4.predict(X_test_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds_xgb4)), mean_absolute_error(y_test, preds_xgb4), r2_score(y_test, preds_xgb4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "### Practical Considerations\n",
    "- How much is it worth to improve (metric) by x ? (From a business / practical point of view)\n",
    "- How much time / computing do I want to spend on improvement?\n",
    "- How often will I be re-training / re-implementing this model?\n",
    "- What is the value of knowing / understanding this dataset / model really well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Parameters in Gradient Boosting\n",
    "There are several approaches to finding the best parameters for your Gradient Boosting Model\n",
    "1. Do a massive \"grid search\"\n",
    "2. Just play around manually\n",
    "3. \"Smart\" parameter search that tries to search promising combinations\n",
    "\n",
    "There are drawbacks to all of these:\n",
    "- Grid search is extremely time consuming\n",
    "- It is difficult to know if you are choosing appropriate parameters and ranges\n",
    "- There may be other considerations than just metric performance (model size, coherence, training time)\n",
    "- Manual approaches are haphazard, attention consuming\n",
    "- Smart approaches are not always as smart as they could be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's tune the max depth\n",
    "\n",
    "md_vals_vec=list(range(1,10))\n",
    "rmse_vec = np.zeros(len(md_vals_vec))\n",
    "for i,md in enumerate(md_vals_vec):\n",
    "    print(f'Training with max_depth {md}')\n",
    "    xgb_temp = xgb.XGBRegressor(max_depth=md, \n",
    "                        n_estimators=5000, learning_rate=.01, \n",
    "         early_stopping_rounds = 10) #, early_stopping_rounds=10)\n",
    "    xgb_temp.fit(X_train_4, y_train, \n",
    "         eval_set=[(X_test_4, y_test)], \n",
    "                 verbose=0)\n",
    "    preds = xgb_temp.predict(X_test_4)\n",
    "    rmse_vec[i] = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "## Note - for newer versions of xgboost, this might scream at you....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot performance vs. max_depth\n",
    "plt.plot(md_vals_vec, rmse_vec, marker='x')\n",
    "np.min(rmse_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's manually explore some parameters one by one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_vals_vec=[.7,.75,.8,.85,.9,.95,1]\n",
    "rmse_vec = np.zeros(len(param_vals_vec))\n",
    "for i,param_val in enumerate(param_vals_vec):\n",
    "    xgb_temp = xgb.XGBRegressor(max_depth=4, \n",
    "                        n_estimators=10000, learning_rate=.01,\n",
    "                        subsample=param_val, early_stopping_rounds = 10)\n",
    "    xgb_temp.fit(X_train_4, y_train, \n",
    "         eval_set=[(X_test_4, y_test)], \n",
    "                 verbose=0)\n",
    "    preds = xgb_temp.predict(X_test_4)\n",
    "    rmse_vec[i] = np.sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(param_vals_vec, rmse_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_vals_vec=[.2,.3,.4,.5,.6,.7, .8,.9, 1]\n",
    "rmse_vec = np.zeros(len(param_vals_vec))\n",
    "for i,param_val in enumerate(param_vals_vec):\n",
    "    xgb_temp = xgb.XGBRegressor(max_depth=4, \n",
    "                        n_estimators=10000, learning_rate=.01,\n",
    "                        subsample=.75, colsample_bynode=param_val, early_stopping_rounds = 10)\n",
    "    xgb_temp.fit(X_train_4, y_train, \n",
    "         eval_set=[(X_test_4, y_test)], \n",
    "                 verbose=0)\n",
    "    preds = xgb_temp.predict(X_test_4)\n",
    "    rmse_vec[i] = np.sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(param_vals_vec, rmse_vec);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(rmse_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_vals_vec=[.01,.1,1,2,3,5,10,20]\n",
    "rmse_vec = np.zeros(len(param_vals_vec))\n",
    "for i,param_val in enumerate(param_vals_vec):\n",
    "    xgb_temp = xgb.XGBRegressor(max_depth=4, \n",
    "                        n_estimators=10000, learning_rate=.01,\n",
    "                        subsample=.75, colsample_bynode=.9, reg_lambda=param_val, early_stopping_rounds = 10)\n",
    "    xgb_temp.fit(X_train_4, y_train, \n",
    "         eval_set=[(X_test_4, y_test)], \n",
    "                 verbose=0)\n",
    "    preds = xgb_temp.predict(X_test_4)\n",
    "    rmse_vec[i] = np.sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(param_vals_vec, rmse_vec);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(rmse_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperopt Package\n",
    "Idea: rather than try and exhaustively search a huge parameter space, focus the search on \"promising\" areas of the search space (based on what you have seen so far).\n",
    "\n",
    "The `hyperopt` package can be a bit confusing and has some limitations, but overall does a reasonably good job of seraching the parameter space.\n",
    "\n",
    "Let's see it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First we must define the \"loss function\"\n",
    "- This takes a set of parameters and output the loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(params):\n",
    "    xgb_base = xgb.XGBRegressor()\n",
    "    xgb_base.set_params(**params)\n",
    "    xgb_base.set_params(**{'learning_rate':.01,\n",
    "                            'n_estimators': 10000,\n",
    "                            'early_stopping_rounds':20},)\n",
    "    xgb_base.fit(X_train_4, y_train, eval_set=[(X_test_4, y_test)], \n",
    "                 verbose=False)\n",
    "    preds = xgb_base.predict(X_test_4)\n",
    "    return(np.sqrt(mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we define the parameter space.  \n",
    "- There are several options to define ranges.\n",
    "    - `randint`: chooses a random integer between a lower and an upper bound\n",
    "    - `choice`: choose from a set of specific values\n",
    "    - `uniform`: choose a (float) in the range\n",
    "    - `quniform`: choose a discrete range of floats\n",
    "    \n",
    "See more at hyperopt documentation:\n",
    "http://hyperopt.github.io/hyperopt/getting-started/search_spaces/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fspace1 = {\n",
    "    'max_depth':hp.randint('max_depth', 2, 6), # Pythonic - means 2 through 5 inclusive\n",
    "    'colsample_bynode': hp.quniform('colsample_bynode',.1,1,.1),\n",
    "    'subsample': hp.quniform('subsample',.3,1,.05),\n",
    "    'reg_lambda': hp.qloguniform('reg_lambda',np.log(.1),np.log(20),.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, we use the `fmin` function and record our trials in a `Trials` object\n",
    "- you can also specify which algorithm to use (http://hyperopt.github.io/hyperopt/#algorithms) (`tpe.suggest` is \"Tree of Parzen Estimators\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials1 = Trials()\n",
    "best = fmin(fn=eval_model, space=fspace1, algo=tpe.suggest, max_evals=100, trials=trials1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials1.trials[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_trial_vals = np.array([t['misc']['vals']['max_depth'] for t in trials1.trials])\n",
    "csbn_trial_vals = np.array([t['misc']['vals']['colsample_bynode'] for t in trials1.trials])\n",
    "ss_trial_vals = np.array([t['misc']['vals']['subsample'] for t in trials1.trials])\n",
    "lambda_trial_vals = np.array([t['misc']['vals']['reg_lambda'] for t in trials1.trials])\n",
    "loss_trial_vals = np.array([t['result']['loss'] for t in trials1.trials])\n",
    "trial_nums = np.array([t['tid'] for t in trials1.trials])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trial_nums, loss_trial_vals, alpha=.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trial_nums, csbn_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trial_nums, md_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(md_trial_vals, loss_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(csbn_trial_vals, loss_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(ss_trial_vals, loss_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.log(lambda_trial_vals), loss_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fspace2 = {\n",
    "    'max_depth':hp.randint('max_depth', 4, 9), # Pythonic - means 4 through 7 inclusive\n",
    "    'colsample_bynode': hp.quniform('colsample_bynode',.1,1,.1),\n",
    "    'subsample': hp.quniform('subsample',.3,1,.05),\n",
    "    'reg_lambda': hp.qloguniform('reg_lambda',np.log(.1),np.log(20),.1),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, we use the `fmin` function and record our trials in a `Trials` object\n",
    "- you can also specify which algorithm to use (http://hyperopt.github.io/hyperopt/#algorithms) (`tpe.suggest` is \"Tree of Parzen Estimators\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials2 = Trials()\n",
    "best2 = fmin(fn=eval_model, space=fspace2, algo=tpe.suggest, max_evals=200, trials=trials2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_trial_vals = np.array([t['misc']['vals']['max_depth'] for t in trials2.trials])\n",
    "csbn_trial_vals = np.array([t['misc']['vals']['colsample_bynode'] for t in trials2.trials])\n",
    "ss_trial_vals = np.array([t['misc']['vals']['subsample'] for t in trials2.trials])\n",
    "lambda_trial_vals = np.array([t['misc']['vals']['reg_lambda'] for t in trials2.trials])\n",
    "loss_trial_vals = np.array([t['result']['loss'] for t in trials2.trials])\n",
    "trial_nums = np.array([t['tid'] for t in trials2.trials])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trial_nums, loss_trial_vals, alpha=.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trial_nums, csbn_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trial_nums, md_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(md_trial_vals, loss_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(csbn_trial_vals, loss_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(ss_trial_vals, loss_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.log10(lambda_trial_vals), loss_trial_vals, alpha=.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can decide to use the parameter set that worked best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_final = xgb.XGBRegressor()\n",
    "xgb_final.set_params(**best2)\n",
    "xgb_final.set_params(**{'learning_rate':.01,\n",
    "                        'n_estimators': 10000,\n",
    "                        'early_stopping_rounds':20},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_final.fit(X_train_4, y_train, eval_set=[(X_test_4, y_test)], \n",
    "             verbose=False)\n",
    "preds = xgb_final.predict(X_test_4)\n",
    "np.sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comments on parameter search\n",
    "- This example was a quite small dataset (~3000 data points), so we were able to run many iterations very quickly.  Typically these searches will take much longer, so it is more important to choose smart ranges.\n",
    "- Note that lots of combinations gave very good results.  Typically if you get the `max_depth` right (using early stopping) and then pick \"pretty good\" values for the rest, you will be in good shape\n",
    "- In practice, other considerations (e.g. model size, parsimony) may come into play.  Generally, you want to pick a \"simpler\" model if the difference in performance is negligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
