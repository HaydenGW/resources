{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StructureBoost Workshop - ODSC Europe 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Multi-Class Classification with StructureBoost\n",
    "In May 2022, StructureBoost was enhanced to permit the exploitation of structure in the *target* variable for multi-class problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it work?\n",
    "- We can define structure based on a set of *partitions* of the state space.  Each partition represents a (meaningful) coarsening of the state space.  Then, when we compute the loss function (log-loss aka cross-entropy aka NLL), we compute it w.r.t. the coarsened state spaces as well as the original, and average the results.\n",
    "\n",
    "By \"the loss function wrt to the partition\", what we mean is:\n",
    "\n",
    "1. Take the predicted probability distribution for the particular test point\n",
    "2. Convert it to a probability distribution on the coarsened state space by summing over the individual values in each coarsened state\n",
    "3. Map the true answer to its respective coarsened state\n",
    "4. Compute the log-loss of the coarsened probability distribution against the coarsened true answer\n",
    "\n",
    "## Reference\n",
    "\"Loss Functions for Classification using Structured Entropy\" B. Lucena - arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "To represent the months of the year (where 1 = January, 2 = Feb, ... 12 = December), we might consider the partition:\n",
    "\n",
    "$\\mathcal{P}_1 = \\{\\{1,2,3\\},\\{4,5,6\\},\\{7,8,9\\},\\{10,11,12\\}\\}$\n",
    "\n",
    "You could think of this as coarsening the months into seasons {winter, spring, summer, fall}.  Then we could use a loss function that is essentially 1/2 the *regular* log-loss and 1/2 log-loss with respect to the partition $\\mathcal{P}_1$ above. The idea, is that this modified loss function will \"reward\" a prediction (penalize it less) for being \"close\" to the right answer (i.e. in the right season if not the right month).\n",
    "\n",
    "To provide better symmetry, we could go further and define three partitions:\n",
    "\n",
    "$\\mathcal{P}_1 = \\{\\{1,2,3\\},\\{4,5,6\\},\\{7,8,9\\},\\{10,11,12\\}\\}$\n",
    "\n",
    "$\\mathcal{P}_2 = \\{\\{2,3,4\\},\\{5,6,7\\},\\{8,9,10\\},\\{11,12,1\\}\\}$\n",
    "\n",
    "$\\mathcal{P}_3 = \\{\\{3,4,5\\},\\{6,7,8\\},\\{9,10,11\\},\\{12,1,2\\}\\}$\n",
    "\n",
    "and have the loss function be weighted .25 for each of the three partitions above and .25 for the standard log-loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import structureboost as stb\n",
    "import ml_insights as mli\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "pd.set_option('display.max_rows',999)\n",
    "pd.set_option('display.max_columns',999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca = pd.read_csv('../data/ca_weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data and Explore\n",
    "As you can see below, this is a dataset where each row represents the weather observations from a particular weather station on a particular date.  We know the min and max temperature (TMIN, TMAX), the amount of precipitation (PRCP), as well as the month of the observation and the county where the weather station is located.\n",
    "\n",
    "California has 58 counties, however, the weather station in Sutter County does not record temperature, so for the purposes of this exercise we are combining Sutter and Yuba counties into a single county \"Sutter_Yuba\" so that there are 57 counties.  You can see below that we have selected 5000 observations from each of the 57 counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285000, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 285000 entries, 0 to 284999\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   county   285000 non-null  object \n",
      " 1   month    285000 non-null  int64  \n",
      " 2   PRCP     285000 non-null  float64\n",
      " 3   TMAX     285000 non-null  float64\n",
      " 4   TMIN     285000 non-null  float64\n",
      " 5   DATE     285000 non-null  object \n",
      " 6   STATION  285000 non-null  object \n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>month</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>DATE</th>\n",
       "      <th>STATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170602</th>\n",
       "      <td>San_Benito</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2007-06-21</td>\n",
       "      <td>USC00044025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43708</th>\n",
       "      <td>El_Dorado</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2010-10-20</td>\n",
       "      <td>USC00046960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43638</th>\n",
       "      <td>El_Dorado</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2011-07-09</td>\n",
       "      <td>USC00048760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33541</th>\n",
       "      <td>Contra_Costa</td>\n",
       "      <td>12</td>\n",
       "      <td>1.89</td>\n",
       "      <td>58.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2001-12-02</td>\n",
       "      <td>USC00045378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81165</th>\n",
       "      <td>Lake</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2005-11-10</td>\n",
       "      <td>USC00041806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              county  month  PRCP  TMAX  TMIN        DATE      STATION\n",
       "170602    San_Benito      6  0.00  84.0  50.0  2007-06-21  USC00044025\n",
       "43708      El_Dorado     10  0.00  76.0  48.0  2010-10-20  USC00046960\n",
       "43638      El_Dorado      7  0.00  75.0  39.0  2011-07-09  USC00048760\n",
       "33541   Contra_Costa     12  1.89  58.0  49.0  2001-12-02  USC00045378\n",
       "81165           Lake     11  0.00  72.0  41.0  2005-11-10  USC00041806"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alameda            5000\n",
       "Orange             5000\n",
       "Plumas             5000\n",
       "Riverside          5000\n",
       "Sacramento         5000\n",
       "San_Benito         5000\n",
       "San_Bernardino     5000\n",
       "San_Diego          5000\n",
       "San_Francisco      5000\n",
       "San_Joaquin        5000\n",
       "San_Luis_Obispo    5000\n",
       "San_Mateo          5000\n",
       "Santa_Barbara      5000\n",
       "Santa_Clara        5000\n",
       "Santa_Cruz         5000\n",
       "Shasta             5000\n",
       "Sierra             5000\n",
       "Siskiyou           5000\n",
       "Solano             5000\n",
       "Sonoma             5000\n",
       "Stanislaus         5000\n",
       "Tehama             5000\n",
       "Trinity            5000\n",
       "Tulare             5000\n",
       "Tuolumne           5000\n",
       "Ventura            5000\n",
       "Yolo               5000\n",
       "Placer             5000\n",
       "Nevada             5000\n",
       "Alpine             5000\n",
       "Napa               5000\n",
       "Amador             5000\n",
       "Butte              5000\n",
       "Calaveras          5000\n",
       "Colusa             5000\n",
       "Contra_Costa       5000\n",
       "Del_Norte          5000\n",
       "El_Dorado          5000\n",
       "Fresno             5000\n",
       "Glenn              5000\n",
       "Humboldt           5000\n",
       "Imperial           5000\n",
       "Inyo               5000\n",
       "Kern               5000\n",
       "Kings              5000\n",
       "Lake               5000\n",
       "Lassen             5000\n",
       "Los_Angeles        5000\n",
       "Madera             5000\n",
       "Marin              5000\n",
       "Mariposa           5000\n",
       "Mendocino          5000\n",
       "Merced             5000\n",
       "Modoc              5000\n",
       "Mono               5000\n",
       "Monterey           5000\n",
       "Sutter_Yuba        5000\n",
       "Name: county, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca.county.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     24772\n",
       "3     24648\n",
       "1     24610\n",
       "7     24416\n",
       "8     24031\n",
       "4     23688\n",
       "10    23673\n",
       "6     23324\n",
       "12    23317\n",
       "9     23063\n",
       "2     22778\n",
       "11    22680\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca.month.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "First, we are going to build a model that tries to predict the month of the year, given the min and max temperature (TMIN, TMAX) and the amount of precipitation (PRCP).  In general, we don't expect to be able to predict the month exactly, but we would like to have an accurate probability distribution on what month it is given the temperatures and precipitation that day.  Thus we will use the `log_loss` to determine the quality of our predictions.\n",
    "\n",
    "Clearly, there is some meaningful *structure* in the target variable month.  We expect the weather in January to be more similar to December than it is to July.  Thus, it is reasonable to expect that we will get better performance if the model is aware of these similarities during training, rather than just knowing that months are different from one another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_ca.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As would be expected, the months are numbered 1 through 12.  StructureBoost requires the target to be integers from 0 to num_classes-1.  Thus, we will create a modified \"month\" variable where December (12) is designated as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = df_ca['month'].copy()\n",
    "tvec[tvec==12] = 0\n",
    "df_ca['month_mod'] = tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_ca.month_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll split the data into training, validation, and test_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = ['TMAX','TMIN','PRCP']\n",
    "target = 'month_mod'\n",
    "\n",
    "X = df_ca.loc[:,feat_list]\n",
    "y = df_ca[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 3), (5000, 3), (100000, 3), (179000, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can configure the sizes of our training, validation and test sets (and the rest will be a \"remainder\")\n",
    "train_size = 1000\n",
    "valid_size = 5000\n",
    "test_size = 100000\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X,y,test_size=test_size, random_state=42)\n",
    "X_train_rem, X_valid, y_train_rem, y_valid = train_test_split(X_train_val, y_train_val, test_size=valid_size, random_state=42)\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X_train_rem, y_train_rem, train_size=train_size, random_state=42)\n",
    "X_train.shape, X_valid.shape, X_test.shape, X_rem.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring StructureBoost Target Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StructureBoost permits two methods for defining the structure on a target variable:\n",
    "\n",
    "    1. Using a fixed set of partitions (with corresponding weights)\n",
    "    2. Using a graph, and randomly choosing partitions from the graph.\n",
    "\n",
    "The idea is that the partitions provide meaningful \"coarsenings\" of the target state space.  The loss function, will then be able to take into account that values in the same *block* of the partition are similar.  The beauty of this approach is that we can use many partitions at the same time.\n",
    "\n",
    "For example, for the months of the year, one might consider that the months of each season tend to have similar weather.  This might lead us to define a partition of the months such as:\n",
    "{Dec, Jan, Feb}, {Mar, Apr, May}, {Jun, Jul, Aug}, {Sep, Oct, Nov}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TMAX': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'TMIN': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'PRCP': {'feature_type': 'numerical', 'max_splits_to_search': 25}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a quick way to get a starting feature configuration that can be modified\n",
    "fc1 = stb.get_basic_config(X_train, stb.default_config_dict())\n",
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will run StructureBoost with no knowledge of the structure of the months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, eval_set_loss = 2.489849939705327\n",
      "i=10, eval_set_loss = 2.3890038754134517\n",
      "i=20, eval_set_loss = 2.323317356598625\n",
      "i=30, eval_set_loss = 2.2766458411224644\n",
      "i=40, eval_set_loss = 2.2435759007115665\n",
      "i=50, eval_set_loss = 2.220499934628192\n",
      "i=60, eval_set_loss = 2.20478900215626\n",
      "i=70, eval_set_loss = 2.19149489202869\n",
      "i=80, eval_set_loss = 2.1822316812467584\n",
      "i=90, eval_set_loss = 2.1757846814964723\n",
      "i=100, eval_set_loss = 2.1714983091914455\n",
      "i=110, eval_set_loss = 2.168198086385436\n",
      "i=120, eval_set_loss = 2.1661761488721445\n",
      "i=130, eval_set_loss = 2.1645733555859317\n",
      "i=140, eval_set_loss = 2.1639437785504327\n",
      "i=150, eval_set_loss = 2.1637088338188217\n",
      "i=160, eval_set_loss = 2.1633924944548113\n",
      "i=170, eval_set_loss = 2.1631352069258067\n",
      "i=180, eval_set_loss = 2.163841534032274\n",
      "Stopping early: curr_loss of 2.163841534032274\n",
      "                                        exceeds compare_loss of 2.1631352069258067\n"
     ]
    }
   ],
   "source": [
    "# Define the StructureBoost model and fit it\n",
    "stb0 = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, \n",
    "                               target_structure=None, learning_rate=.02)\n",
    "stb0.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1546700363650797"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on a test set, and then evaluate the log_loss\n",
    "test_preds_0 = stb0.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will configure StructureBoost using a fixed set of partitions.  We will group the months in \"blocks\" of size 3 - and there are 3 different partitions, depending on where we start grouping.\n",
    "\n",
    "StructureBoost assumes you will always use the singleton partition as part of the partition set.  We give a weight using the `singleton_weight` parameter.\n",
    "\n",
    "The weights for the other partitions in the partition set must be designated by the `partition_weight_vec` parameter.  The weights should sum to 1.  (you will get a warning, but not an error, if this is not the case).\n",
    "\n",
    "In the example below, the singleton partition has weight 0.4 and the other 3 partitions each have weight 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we configure the target structure to use a fixed, weighted partition\n",
    "ts1 = {}\n",
    "ts1['partition_type'] = 'fixed'\n",
    "ts1['singleton_weight'] = .4\n",
    "ts1['partition_list'] = [ [[0,1,2],[3,4,5],[6,7,8],[9,10,11]],\n",
    "                         [[1,2,3],[4,5,6],[7,8,9],[10,11,0]],\n",
    "                         [[2,3,4],[5,6,7],[8,9,10],[11,0,1]] ]\n",
    "ts1['partition_weight_vec'] = [.2,.2,.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, eval_set_loss = 2.489849939705327\n",
      "i=10, eval_set_loss = 2.3978186756273803\n",
      "i=20, eval_set_loss = 2.3328466771006706\n",
      "i=30, eval_set_loss = 2.2853950804675973\n",
      "i=40, eval_set_loss = 2.2508550213121996\n",
      "i=50, eval_set_loss = 2.225397902189174\n",
      "i=60, eval_set_loss = 2.2062610301482977\n",
      "i=70, eval_set_loss = 2.1916442943952608\n",
      "i=80, eval_set_loss = 2.1810994840433024\n",
      "i=90, eval_set_loss = 2.1737560893538186\n",
      "i=100, eval_set_loss = 2.167654810243412\n",
      "i=110, eval_set_loss = 2.1633841174600517\n",
      "i=120, eval_set_loss = 2.160973207520432\n",
      "i=130, eval_set_loss = 2.158068223949387\n",
      "i=140, eval_set_loss = 2.156355853269231\n",
      "i=150, eval_set_loss = 2.155437440473987\n",
      "i=160, eval_set_loss = 2.154206251313224\n",
      "i=170, eval_set_loss = 2.154014085756576\n",
      "i=180, eval_set_loss = 2.1539950403781005\n",
      "i=190, eval_set_loss = 2.1546558292411584\n",
      "Stopping early: curr_loss of 2.1546558292411584\n",
      "                                        exceeds compare_loss of 2.1539950403781005\n"
     ]
    }
   ],
   "source": [
    "# Define the StructureBoost model and fit it\n",
    "stb1 = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, \n",
    "                               target_structure=ts1, learning_rate=.02)\n",
    "\n",
    "stb1.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1456820054584016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on a test set, and then evaluate the log_loss\n",
    "test_preds_1 = stb1.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases it may be tedious to write out a fixed partition.  There is an alternative, when the desired structure can be represented in terms of a *graph*.  In this case we can simply provide the graph and ask StructureBoost to randomly find partitions of the graph (which respect the structure of the graph).  Then, at each iteration, a different, randomly chosen partition (or partitions) of the graph will be used, in conjunction with the singleton partition.\n",
    "\n",
    "We show how to configure this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11},\n",
       " {frozenset({3, 4}),\n",
       "  frozenset({2, 3}),\n",
       "  frozenset({9, 10}),\n",
       "  frozenset({1, 2}),\n",
       "  frozenset({4, 5}),\n",
       "  frozenset({0, 1}),\n",
       "  frozenset({6, 7}),\n",
       "  frozenset({8, 9}),\n",
       "  frozenset({7, 8}),\n",
       "  frozenset({5, 6}),\n",
       "  frozenset({0, 11}),\n",
       "  frozenset({10, 11})})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we must define the appropriate graph\n",
    "cycle_0_11 = stb.graphs.cycle_int_graph(0,11)\n",
    "cycle_0_11.vertices, cycle_0_11.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we configure the target structure to use a variable (random) partition\n",
    "# We must specify how many partitions we want, and of what sizes\n",
    "# Note: partition size refers to the *number* of blocks, not the size of the blocks\n",
    "\n",
    "ts2a = {}\n",
    "ts2a['partition_type'] = 'variable'\n",
    "ts2a['target_graph'] = cycle_0_11\n",
    "ts2a['singleton_weight'] = .5\n",
    "ts2a['num_partitions'] = 1\n",
    "ts2a['random_partition_size'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rp_method' not configured. Defaulting to 'span_tree'\n",
      "i=0, eval_set_loss = 2.489849939705327\n",
      "i=10, eval_set_loss = 2.3965954009907424\n",
      "i=20, eval_set_loss = 2.3344199985192082\n",
      "i=30, eval_set_loss = 2.2878050931268468\n",
      "i=40, eval_set_loss = 2.25297656652924\n",
      "i=50, eval_set_loss = 2.2277720960113054\n",
      "i=60, eval_set_loss = 2.209395686274858\n",
      "i=70, eval_set_loss = 2.1954311916390035\n",
      "i=80, eval_set_loss = 2.1849393990460877\n",
      "i=90, eval_set_loss = 2.1778675885342387\n",
      "i=100, eval_set_loss = 2.1717430719766524\n",
      "i=110, eval_set_loss = 2.1674721151531977\n",
      "i=120, eval_set_loss = 2.1633440976573084\n",
      "i=130, eval_set_loss = 2.161875960612751\n",
      "i=140, eval_set_loss = 2.160639320269018\n",
      "i=150, eval_set_loss = 2.159234626445285\n",
      "i=160, eval_set_loss = 2.1595098994151902\n",
      "Stopping early: curr_loss of 2.1595098994151902\n",
      "                                        exceeds compare_loss of 2.159234626445285\n"
     ]
    }
   ],
   "source": [
    "stb2a = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, \n",
    "                               target_structure=ts2a, learning_rate=.02)\n",
    "\n",
    "stb2a.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.150674329278085"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on a test set, and then evaluate the log_loss\n",
    "test_preds_2a = stb2a.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time, let's configure it so that there are multiple partitions, of various sizes\n",
    "# Each partition is given the same weight (= (1-singleton_weight)/num_partitions))\n",
    "ts2b = {}\n",
    "ts2b['partition_type'] = 'variable'\n",
    "ts2b['target_graph'] = cycle_0_11\n",
    "ts2b['singleton_weight'] = .5\n",
    "ts2b['num_partitions'] = 5\n",
    "ts2b['random_partition_size'] = [3,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rp_method' not configured. Defaulting to 'span_tree'\n",
      "i=0, eval_set_loss = 2.489849939705327\n",
      "i=10, eval_set_loss = 2.396458793349196\n",
      "i=20, eval_set_loss = 2.3312907691941027\n",
      "i=30, eval_set_loss = 2.283036590151717\n",
      "i=40, eval_set_loss = 2.2491768534939016\n",
      "i=50, eval_set_loss = 2.2238551601987813\n",
      "i=60, eval_set_loss = 2.205904129490063\n",
      "i=70, eval_set_loss = 2.192107713685235\n",
      "i=80, eval_set_loss = 2.182162356618174\n",
      "i=90, eval_set_loss = 2.1746971686891166\n",
      "i=100, eval_set_loss = 2.1691963748380467\n",
      "i=110, eval_set_loss = 2.165860844140398\n",
      "i=120, eval_set_loss = 2.1622678875807337\n",
      "i=130, eval_set_loss = 2.160766194167346\n",
      "i=140, eval_set_loss = 2.159267706123605\n",
      "i=150, eval_set_loss = 2.158557564284738\n",
      "i=160, eval_set_loss = 2.15831444017402\n",
      "i=170, eval_set_loss = 2.158333727175485\n",
      "Stopping early: curr_loss of 2.158333727175485\n",
      "                                        exceeds compare_loss of 2.15831444017402\n"
     ]
    }
   ],
   "source": [
    "stb2b = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, \n",
    "                               target_structure=ts2b, learning_rate=.02)\n",
    "\n",
    "stb2b.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.149831148755294"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on a test set, and then evaluate the log_loss\n",
    "test_preds_2b = stb2b.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_county_graph_mod = stb.graphs.mod_CA_57_county_graph()\n",
    "county_graph_int, map_dict = stb.graphs.integerize_graph(ca_county_graph_mod)\n",
    "df_ca['county_int'] = df_ca.county.apply(lambda x: map_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({3, 4}),\n",
       " frozenset({2, 3}),\n",
       " frozenset({11, 12}),\n",
       " frozenset({9, 10}),\n",
       " frozenset({1, 2}),\n",
       " frozenset({4, 5}),\n",
       " frozenset({6, 7}),\n",
       " frozenset({8, 9}),\n",
       " frozenset({7, 8}),\n",
       " frozenset({1, 12}),\n",
       " frozenset({5, 6}),\n",
       " frozenset({10, 11})}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_graph = stb.graphs.cycle_int_graph(1,12)\n",
    "month_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = ['TMAX','TMIN','PRCP','month']\n",
    "target = 'county_int'\n",
    "\n",
    "X = df_ca.loc[:,feat_list]\n",
    "y = df_ca[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 4), (5000, 4), (100000, 4), (179000, 4))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can configure the sizes of our training, validation and test sets (and the rest will be a \"remainder\")\n",
    "train_size = 1000\n",
    "valid_size = 5000\n",
    "test_size = 100000\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X,y,test_size=test_size, random_state=42)\n",
    "X_train_rem, X_valid, y_train_rem, y_valid = train_test_split(X_train_val, y_train_val, test_size=valid_size, random_state=42)\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X_train_rem, y_train_rem, train_size=train_size, random_state=42)\n",
    "X_train.shape, X_valid.shape, X_test.shape, X_rem.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TMAX': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'TMIN': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'PRCP': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'month': {'feature_type': 'categorical_int',\n",
       "  'max_splits_to_search': 25,\n",
       "  'graph': <structureboost.graphs.graph_undirected at 0x13a6dc9a0>,\n",
       "  'split_method': 'span_tree',\n",
       "  'num_span_trees': 1}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a quick way to get a starting feature configuration that can be modified\n",
    "fc2 = stb.get_basic_config(X_train, stb.default_config_dict())\n",
    "fc2['month']['feature_type'] = 'categorical_int'\n",
    "fc2['month']['graph'] = month_graph\n",
    "fc2['month']['split_method'] = 'span_tree'\n",
    "fc2['month']['num_span_trees']=1\n",
    "fc2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts3 = {}\n",
    "ts3['partition_type'] = 'variable'\n",
    "ts3['target_graph'] = county_graph_int\n",
    "ts3['singleton_weight'] = .2\n",
    "ts3['num_partitions'] = 5\n",
    "ts3['random_partition_size'] = [5,8,10,15,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rp_method' not configured. Defaulting to 'span_tree'\n",
      "i=0, eval_set_loss = 4.0889686351661485\n",
      "i=10, eval_set_loss = 4.042645753445942\n",
      "i=20, eval_set_loss = 4.004767702599326\n",
      "i=30, eval_set_loss = 3.9746368380533714\n",
      "i=40, eval_set_loss = 3.950236715175167\n",
      "i=50, eval_set_loss = 3.928950593175426\n",
      "i=60, eval_set_loss = 3.912449577215877\n",
      "i=70, eval_set_loss = 3.894872327421867\n",
      "i=80, eval_set_loss = 3.883244069117131\n",
      "i=90, eval_set_loss = 3.872033096833672\n",
      "i=100, eval_set_loss = 3.862491440087408\n",
      "i=110, eval_set_loss = 3.8531888569327655\n",
      "i=120, eval_set_loss = 3.847098978824316\n",
      "i=130, eval_set_loss = 3.840284024354076\n",
      "i=140, eval_set_loss = 3.8351503617897413\n",
      "i=150, eval_set_loss = 3.833048770174251\n",
      "i=160, eval_set_loss = 3.829374725833859\n",
      "i=170, eval_set_loss = 3.8269484779021017\n",
      "i=180, eval_set_loss = 3.8245154128789305\n",
      "i=190, eval_set_loss = 3.822913060438421\n",
      "i=200, eval_set_loss = 3.8211496653871744\n",
      "i=210, eval_set_loss = 3.8196756014909625\n",
      "i=220, eval_set_loss = 3.819395019041868\n",
      "i=230, eval_set_loss = 3.818722614104951\n",
      "i=240, eval_set_loss = 3.8178658945975394\n",
      "i=250, eval_set_loss = 3.817444106732226\n",
      "i=260, eval_set_loss = 3.817170135325585\n",
      "i=270, eval_set_loss = 3.817852750943431\n",
      "Stopping early: curr_loss of 3.817852750943431\n",
      "                                        exceeds compare_loss of 3.817170135325585\n"
     ]
    }
   ],
   "source": [
    "stb3 = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc2, num_classes=57, \n",
    "                               target_structure=ts3, learning_rate=.02)\n",
    "\n",
    "stb3.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.815877539351981"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_a = stb3.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TMAX': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'TMIN': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'PRCP': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'month': {'feature_type': 'categorical_int',\n",
       "  'max_splits_to_search': 25,\n",
       "  'graph': <structureboost.graphs.graph_undirected at 0x13a6dc9a0>,\n",
       "  'split_method': 'span_tree',\n",
       "  'num_span_trees': 1}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a quick way to get a starting feature configuration that can be modified\n",
    "fc2 = stb.get_basic_config(X_train, stb.default_config_dict())\n",
    "fc2['month']['feature_type'] = 'categorical_int'\n",
    "fc2['month']['graph'] = month_graph\n",
    "fc2['month']['split_method'] = 'span_tree'\n",
    "fc2['month']['num_span_trees']=1\n",
    "fc2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, eval_set_loss = 4.0889686351661485\n",
      "i=10, eval_set_loss = 4.030601239746914\n",
      "i=20, eval_set_loss = 3.988457349832679\n",
      "i=30, eval_set_loss = 3.9561754087644134\n",
      "i=40, eval_set_loss = 3.9306326791157624\n",
      "i=50, eval_set_loss = 3.9119014535122885\n",
      "i=60, eval_set_loss = 3.8961946080204877\n",
      "i=70, eval_set_loss = 3.8830705409979243\n",
      "i=80, eval_set_loss = 3.870298136121246\n",
      "i=90, eval_set_loss = 3.861322214989765\n",
      "i=100, eval_set_loss = 3.8555840526286804\n",
      "i=110, eval_set_loss = 3.852242928553128\n",
      "i=120, eval_set_loss = 3.8480376844580686\n",
      "i=130, eval_set_loss = 3.845561124772609\n",
      "i=140, eval_set_loss = 3.8441986854994474\n",
      "i=150, eval_set_loss = 3.842242013640623\n",
      "i=160, eval_set_loss = 3.8420865420941657\n",
      "i=170, eval_set_loss = 3.8419143001817355\n",
      "i=180, eval_set_loss = 3.8432377027427385\n",
      "Stopping early: curr_loss of 3.8432377027427385\n",
      "                                        exceeds compare_loss of 3.8419143001817355\n"
     ]
    }
   ],
   "source": [
    "stb4 = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc2, num_classes=57, \n",
    "                               target_structure=None, learning_rate=.02)\n",
    "stb4.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8420796364236356"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_b = stb4.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap-up\n",
    "\n",
    "- ### Check out / Subscribe to my YouTube channel: https://www.youtube.com/numeristical\n",
    "- ### Please rate this talk on the ODSC app!\n",
    "- ### If you find the structureboost package useful, please give it a star on Github!\n",
    "- ### Questions or problems with StructureBoost - email me: brian@numeristical.com\n",
    "- ### Make an account at www.numeristical.com to be added to Slack / Discord\n",
    "- ### Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rigorous testing, Varying the singleton weight\n",
    "Let's see how this does as we vary the singleton weight from 0.0 to 1.0: Note that a singleton weight of 0 is not recommended, as it means there is no \"incentive\" to get the month exactly right.  A singleton weight of 1 means that we are not using the structure at all - it is equivalent to setting `target_structure=None` (using a classical approach to multi-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_list = ['TMAX','TMIN','PRCP']\n",
    "target = 'month_mod'\n",
    "\n",
    "X = df_ca.loc[:,feat_list]\n",
    "y = df_ca[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singleton weight = 0.0\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.4096418619946536\n",
      "i=20, eval_set_loss = 2.350241873907473\n",
      "i=30, eval_set_loss = 2.302984140415745\n",
      "i=40, eval_set_loss = 2.266317726926798\n",
      "i=50, eval_set_loss = 2.2374578343515314\n",
      "i=60, eval_set_loss = 2.2148654898824445\n",
      "i=70, eval_set_loss = 2.1972749629228683\n",
      "i=80, eval_set_loss = 2.18322895500837\n",
      "i=90, eval_set_loss = 2.1726163092852513\n",
      "i=100, eval_set_loss = 2.1639604459762594\n",
      "i=110, eval_set_loss = 2.1564659693582335\n",
      "i=120, eval_set_loss = 2.1505562924596897\n",
      "i=130, eval_set_loss = 2.1458721098040567\n",
      "i=140, eval_set_loss = 2.1417765375320243\n",
      "i=150, eval_set_loss = 2.1382684729901973\n",
      "i=160, eval_set_loss = 2.1353275094036137\n",
      "i=170, eval_set_loss = 2.132663130877232\n",
      "i=180, eval_set_loss = 2.130251179830158\n",
      "i=190, eval_set_loss = 2.128411476565908\n",
      "i=200, eval_set_loss = 2.1265722483229785\n",
      "i=210, eval_set_loss = 2.125059460483738\n",
      "i=220, eval_set_loss = 2.1237233330965726\n",
      "i=230, eval_set_loss = 2.122402189720522\n",
      "i=240, eval_set_loss = 2.121320945889915\n",
      "i=250, eval_set_loss = 2.120326141813428\n",
      "i=260, eval_set_loss = 2.1193209079147035\n",
      "i=270, eval_set_loss = 2.11856754353696\n",
      "i=280, eval_set_loss = 2.117840116556028\n",
      "i=290, eval_set_loss = 2.1171751980768883\n",
      "i=300, eval_set_loss = 2.116651699106806\n",
      "i=310, eval_set_loss = 2.1163074656859004\n",
      "i=320, eval_set_loss = 2.1158409652757597\n",
      "i=330, eval_set_loss = 2.1151851013816443\n",
      "i=340, eval_set_loss = 2.114823058688001\n",
      "i=350, eval_set_loss = 2.114390251078853\n",
      "i=360, eval_set_loss = 2.114207840683027\n",
      "i=370, eval_set_loss = 2.1138274083417032\n",
      "i=380, eval_set_loss = 2.113418745216529\n",
      "i=390, eval_set_loss = 2.1131086646370116\n",
      "i=400, eval_set_loss = 2.113072975977964\n",
      "i=410, eval_set_loss = 2.1127740890454674\n",
      "i=420, eval_set_loss = 2.112540838856026\n",
      "i=430, eval_set_loss = 2.112328689141851\n",
      "i=440, eval_set_loss = 2.112272771660908\n",
      "i=450, eval_set_loss = 2.112353708586533\n",
      "Stopping early: curr_loss of 2.112353708586533\n",
      "                                        exceeds compare_loss of 2.112272771660908\n",
      "Singleton weight = 0.1\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.3922216094239688\n",
      "i=20, eval_set_loss = 2.324024411604449\n",
      "i=30, eval_set_loss = 2.2737973293924596\n",
      "i=40, eval_set_loss = 2.2365305963976647\n",
      "i=50, eval_set_loss = 2.2083908024249763\n",
      "i=60, eval_set_loss = 2.187063559109744\n",
      "i=70, eval_set_loss = 2.170856456916425\n",
      "i=80, eval_set_loss = 2.1582214126851533\n",
      "i=90, eval_set_loss = 2.148764628205879\n",
      "i=100, eval_set_loss = 2.14111223842408\n",
      "i=110, eval_set_loss = 2.13490320038197\n",
      "i=120, eval_set_loss = 2.1300784192846005\n",
      "i=130, eval_set_loss = 2.1260423785000557\n",
      "i=140, eval_set_loss = 2.1229549751532275\n",
      "i=150, eval_set_loss = 2.1202694184541966\n",
      "i=160, eval_set_loss = 2.118250003240021\n",
      "i=170, eval_set_loss = 2.1163540566366015\n",
      "i=180, eval_set_loss = 2.1151836269398525\n",
      "i=190, eval_set_loss = 2.114251164964094\n",
      "i=200, eval_set_loss = 2.1129245105265073\n",
      "i=210, eval_set_loss = 2.1121839111053315\n",
      "i=220, eval_set_loss = 2.111883994282806\n",
      "i=230, eval_set_loss = 2.1113284565764014\n",
      "i=240, eval_set_loss = 2.111032587638375\n",
      "i=250, eval_set_loss = 2.1106449618787426\n",
      "i=260, eval_set_loss = 2.1103357627665975\n",
      "i=270, eval_set_loss = 2.1102264503363344\n",
      "i=280, eval_set_loss = 2.110334911234504\n",
      "Stopping early: curr_loss of 2.110334911234504\n",
      "                                        exceeds compare_loss of 2.1102264503363344\n",
      "Singleton weight = 0.2\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.39142521451483\n",
      "i=20, eval_set_loss = 2.3228232508882347\n",
      "i=30, eval_set_loss = 2.2724486273806166\n",
      "i=40, eval_set_loss = 2.235233416881842\n",
      "i=50, eval_set_loss = 2.20752168446534\n",
      "i=60, eval_set_loss = 2.1862695758140385\n",
      "i=70, eval_set_loss = 2.1700932923634073\n",
      "i=80, eval_set_loss = 2.1574156952185333\n",
      "i=90, eval_set_loss = 2.1479354324435573\n",
      "i=100, eval_set_loss = 2.1404663880237633\n",
      "i=110, eval_set_loss = 2.134513343013711\n",
      "i=120, eval_set_loss = 2.1296432556634763\n",
      "i=130, eval_set_loss = 2.125979728494766\n",
      "i=140, eval_set_loss = 2.1230939402810183\n",
      "i=150, eval_set_loss = 2.1205105393408483\n",
      "i=160, eval_set_loss = 2.1185544739059545\n",
      "i=170, eval_set_loss = 2.116732416732535\n",
      "i=180, eval_set_loss = 2.1152415763116257\n",
      "i=190, eval_set_loss = 2.114398451287684\n",
      "i=200, eval_set_loss = 2.1133755625985917\n",
      "i=210, eval_set_loss = 2.112455261088565\n",
      "i=220, eval_set_loss = 2.1121981983502307\n",
      "i=230, eval_set_loss = 2.11185222947821\n",
      "i=240, eval_set_loss = 2.1113885562098296\n",
      "i=250, eval_set_loss = 2.11102358743315\n",
      "i=260, eval_set_loss = 2.1105535511773397\n",
      "i=270, eval_set_loss = 2.1102853858569706\n",
      "i=280, eval_set_loss = 2.1100639569794564\n",
      "i=290, eval_set_loss = 2.109904720335622\n",
      "i=300, eval_set_loss = 2.110087855763248\n",
      "Stopping early: curr_loss of 2.110087855763248\n",
      "                                        exceeds compare_loss of 2.109904720335622\n",
      "Singleton weight = 0.3\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.390334061365302\n",
      "i=20, eval_set_loss = 2.3213509549532367\n",
      "i=30, eval_set_loss = 2.2707736407010386\n",
      "i=40, eval_set_loss = 2.233662855293158\n",
      "i=50, eval_set_loss = 2.2060021696352807\n",
      "i=60, eval_set_loss = 2.1846703053198264\n",
      "i=70, eval_set_loss = 2.168462917385713\n",
      "i=80, eval_set_loss = 2.156052514133638\n",
      "i=90, eval_set_loss = 2.146400726825191\n",
      "i=100, eval_set_loss = 2.1388018684785806\n",
      "i=110, eval_set_loss = 2.1328234306573215\n",
      "i=120, eval_set_loss = 2.1279689796732035\n",
      "i=130, eval_set_loss = 2.1245998039482976\n",
      "i=140, eval_set_loss = 2.1212668168682924\n",
      "i=150, eval_set_loss = 2.118997492259953\n",
      "i=160, eval_set_loss = 2.1172471853816046\n",
      "i=170, eval_set_loss = 2.1156947108473103\n",
      "i=180, eval_set_loss = 2.1144166907779276\n",
      "i=190, eval_set_loss = 2.1132782204571554\n",
      "i=200, eval_set_loss = 2.112084236958254\n",
      "i=210, eval_set_loss = 2.111357683545974\n",
      "i=220, eval_set_loss = 2.1107476725194925\n",
      "i=230, eval_set_loss = 2.1103884554292596\n",
      "i=240, eval_set_loss = 2.1101337433853065\n",
      "i=250, eval_set_loss = 2.1099965800103164\n",
      "i=260, eval_set_loss = 2.109407936236178\n",
      "i=270, eval_set_loss = 2.1092396952730463\n",
      "i=280, eval_set_loss = 2.1090461406106606\n",
      "i=290, eval_set_loss = 2.108837258634457\n",
      "i=300, eval_set_loss = 2.1091444057125894\n",
      "Stopping early: curr_loss of 2.1091444057125894\n",
      "                                        exceeds compare_loss of 2.108837258634457\n",
      "Singleton weight = 0.4\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.389214326738861\n",
      "i=20, eval_set_loss = 2.319646326892136\n",
      "i=30, eval_set_loss = 2.268970949777244\n",
      "i=40, eval_set_loss = 2.2318396555951265\n",
      "i=50, eval_set_loss = 2.2039635215495634\n",
      "i=60, eval_set_loss = 2.183477967903849\n",
      "i=70, eval_set_loss = 2.1675262274173352\n",
      "i=80, eval_set_loss = 2.155290109867594\n",
      "i=90, eval_set_loss = 2.1460974536131974\n",
      "i=100, eval_set_loss = 2.1387613068036866\n",
      "i=110, eval_set_loss = 2.1327935889751095\n",
      "i=120, eval_set_loss = 2.1281682765450003\n",
      "i=130, eval_set_loss = 2.1245032084223223\n",
      "i=140, eval_set_loss = 2.1215848436644924\n",
      "i=150, eval_set_loss = 2.119257514951426\n",
      "i=160, eval_set_loss = 2.117267817678926\n",
      "i=170, eval_set_loss = 2.115706385535344\n",
      "i=180, eval_set_loss = 2.114668845802702\n",
      "i=190, eval_set_loss = 2.1137417519217956\n",
      "i=200, eval_set_loss = 2.112704026551425\n",
      "i=210, eval_set_loss = 2.112288452241814\n",
      "i=220, eval_set_loss = 2.111720292576609\n",
      "i=230, eval_set_loss = 2.1113238282449966\n",
      "i=240, eval_set_loss = 2.1111255632189923\n",
      "i=250, eval_set_loss = 2.1110518321533114\n",
      "i=260, eval_set_loss = 2.110669660167602\n",
      "i=270, eval_set_loss = 2.110473500658299\n",
      "i=280, eval_set_loss = 2.1103716394241565\n",
      "i=290, eval_set_loss = 2.1103266398775893\n",
      "i=300, eval_set_loss = 2.1103657889656633\n",
      "Stopping early: curr_loss of 2.1103657889656633\n",
      "                                        exceeds compare_loss of 2.1103266398775893\n",
      "Singleton weight = 0.5\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.3880942075041136\n",
      "i=20, eval_set_loss = 2.3181171671891443\n",
      "i=30, eval_set_loss = 2.2679147777745197\n",
      "i=40, eval_set_loss = 2.2312236217388652\n",
      "i=50, eval_set_loss = 2.203702131630775\n",
      "i=60, eval_set_loss = 2.1826356804315883\n",
      "i=70, eval_set_loss = 2.1667705009645206\n",
      "i=80, eval_set_loss = 2.1546332933995744\n",
      "i=90, eval_set_loss = 2.145273501143739\n",
      "i=100, eval_set_loss = 2.1381575440133718\n",
      "i=110, eval_set_loss = 2.1321111192271904\n",
      "i=120, eval_set_loss = 2.1276036102045133\n",
      "i=130, eval_set_loss = 2.124229450514343\n",
      "i=140, eval_set_loss = 2.121507451550146\n",
      "i=150, eval_set_loss = 2.1196749273716256\n",
      "i=160, eval_set_loss = 2.1179043762091356\n",
      "i=170, eval_set_loss = 2.1164594578845333\n",
      "i=180, eval_set_loss = 2.1149185826599695\n",
      "i=190, eval_set_loss = 2.113965316241729\n",
      "i=200, eval_set_loss = 2.112876797392822\n",
      "i=210, eval_set_loss = 2.1122775416489894\n",
      "i=220, eval_set_loss = 2.1117649313103275\n",
      "i=230, eval_set_loss = 2.111175963992365\n",
      "i=240, eval_set_loss = 2.110814041484155\n",
      "i=250, eval_set_loss = 2.110579791676945\n",
      "i=260, eval_set_loss = 2.1106293267934575\n",
      "Stopping early: curr_loss of 2.1106293267934575\n",
      "                                        exceeds compare_loss of 2.110579791676945\n",
      "Singleton weight = 0.6\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.3864900828634994\n",
      "i=20, eval_set_loss = 2.3160430870798794\n",
      "i=30, eval_set_loss = 2.265920254762983\n",
      "i=40, eval_set_loss = 2.229344372047814\n",
      "i=50, eval_set_loss = 2.2020223895750783\n",
      "i=60, eval_set_loss = 2.1811711588481963\n",
      "i=70, eval_set_loss = 2.1652131344830066\n",
      "i=80, eval_set_loss = 2.153436444756121\n",
      "i=90, eval_set_loss = 2.1444655838590085\n",
      "i=100, eval_set_loss = 2.137390525929107\n",
      "i=110, eval_set_loss = 2.13159962149496\n",
      "i=120, eval_set_loss = 2.127130215899464\n",
      "i=130, eval_set_loss = 2.1238328966829547\n",
      "i=140, eval_set_loss = 2.1211433277467333\n",
      "i=150, eval_set_loss = 2.119037445842137\n",
      "i=160, eval_set_loss = 2.1171454891432884\n",
      "i=170, eval_set_loss = 2.1157061611796544\n",
      "i=180, eval_set_loss = 2.1145964122048135\n",
      "i=190, eval_set_loss = 2.1137360883246035\n",
      "i=200, eval_set_loss = 2.1129252237970793\n",
      "i=210, eval_set_loss = 2.112539672854269\n",
      "i=220, eval_set_loss = 2.112055279771867\n",
      "i=230, eval_set_loss = 2.1116022021715364\n",
      "i=240, eval_set_loss = 2.111297541670715\n",
      "i=250, eval_set_loss = 2.1111078559992276\n",
      "i=260, eval_set_loss = 2.110985527665506\n",
      "i=270, eval_set_loss = 2.1109366156803153\n",
      "i=280, eval_set_loss = 2.110618220393198\n",
      "i=290, eval_set_loss = 2.1106365660332216\n",
      "Stopping early: curr_loss of 2.1106365660332216\n",
      "                                        exceeds compare_loss of 2.110618220393198\n",
      "Singleton weight = 0.7\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.384558163294086\n",
      "i=20, eval_set_loss = 2.3138737185087623\n",
      "i=30, eval_set_loss = 2.26303689087223\n",
      "i=40, eval_set_loss = 2.2263120813353314\n",
      "i=50, eval_set_loss = 2.199470993818979\n",
      "i=60, eval_set_loss = 2.179407136136062\n",
      "i=70, eval_set_loss = 2.1634157523580297\n",
      "i=80, eval_set_loss = 2.151587762144092\n",
      "i=90, eval_set_loss = 2.142678186468908\n",
      "i=100, eval_set_loss = 2.135844288515945\n",
      "i=110, eval_set_loss = 2.130541113075088\n",
      "i=120, eval_set_loss = 2.126016374518223\n",
      "i=130, eval_set_loss = 2.1227861668853025\n",
      "i=140, eval_set_loss = 2.1200439131052766\n",
      "i=150, eval_set_loss = 2.1181239772686693\n",
      "i=160, eval_set_loss = 2.116785003078672\n",
      "i=170, eval_set_loss = 2.115430861239806\n",
      "i=180, eval_set_loss = 2.114390874121914\n",
      "i=190, eval_set_loss = 2.113451144571611\n",
      "i=200, eval_set_loss = 2.1125203943426976\n",
      "i=210, eval_set_loss = 2.11208250992233\n",
      "i=220, eval_set_loss = 2.111707983150618\n",
      "i=230, eval_set_loss = 2.111326444866649\n",
      "i=240, eval_set_loss = 2.1112477469011077\n",
      "i=250, eval_set_loss = 2.1111641940674883\n",
      "i=260, eval_set_loss = 2.111029746191731\n",
      "i=270, eval_set_loss = 2.110957326166994\n",
      "i=280, eval_set_loss = 2.1108601008841594\n",
      "i=290, eval_set_loss = 2.1108082370988135\n",
      "i=300, eval_set_loss = 2.110923834593512\n",
      "Stopping early: curr_loss of 2.110923834593512\n",
      "                                        exceeds compare_loss of 2.1108082370988135\n",
      "Singleton weight = 0.8\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.3819437105514707\n",
      "i=20, eval_set_loss = 2.310772397945067\n",
      "i=30, eval_set_loss = 2.2599462289780257\n",
      "i=40, eval_set_loss = 2.22356220575729\n",
      "i=50, eval_set_loss = 2.1968302627983927\n",
      "i=60, eval_set_loss = 2.1766781883074198\n",
      "i=70, eval_set_loss = 2.161225136637636\n",
      "i=80, eval_set_loss = 2.149884639717135\n",
      "i=90, eval_set_loss = 2.141130025903511\n",
      "i=100, eval_set_loss = 2.134010770774563\n",
      "i=110, eval_set_loss = 2.1288046219067995\n",
      "i=120, eval_set_loss = 2.124861549199345\n",
      "i=130, eval_set_loss = 2.121945285565522\n",
      "i=140, eval_set_loss = 2.1194929070072592\n",
      "i=150, eval_set_loss = 2.1175661819188956\n",
      "i=160, eval_set_loss = 2.1160414520912694\n",
      "i=170, eval_set_loss = 2.1148521433413774\n",
      "i=180, eval_set_loss = 2.1137540691986567\n",
      "i=190, eval_set_loss = 2.112888904250501\n",
      "i=200, eval_set_loss = 2.1118162405471215\n",
      "i=210, eval_set_loss = 2.111455355662653\n",
      "i=220, eval_set_loss = 2.111094821866463\n",
      "i=230, eval_set_loss = 2.1106781749297507\n",
      "i=240, eval_set_loss = 2.110564604178621\n",
      "i=250, eval_set_loss = 2.110565418597336\n",
      "Stopping early: curr_loss of 2.110565418597336\n",
      "                                        exceeds compare_loss of 2.110564604178621\n",
      "Singleton weight = 0.9\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.3791309195879164\n",
      "i=20, eval_set_loss = 2.3079177007547544\n",
      "i=30, eval_set_loss = 2.2573700668875816\n",
      "i=40, eval_set_loss = 2.221529150606196\n",
      "i=50, eval_set_loss = 2.195109066729669\n",
      "i=60, eval_set_loss = 2.1752120144788116\n",
      "i=70, eval_set_loss = 2.160134222743474\n",
      "i=80, eval_set_loss = 2.1488791595515466\n",
      "i=90, eval_set_loss = 2.1405118129617184\n",
      "i=100, eval_set_loss = 2.1339724089046466\n",
      "i=110, eval_set_loss = 2.12880694807079\n",
      "i=120, eval_set_loss = 2.124740256472076\n",
      "i=130, eval_set_loss = 2.1219055817711547\n",
      "i=140, eval_set_loss = 2.119570695520704\n",
      "i=150, eval_set_loss = 2.117550894060971\n",
      "i=160, eval_set_loss = 2.1161689714800946\n",
      "i=170, eval_set_loss = 2.1149825540899156\n",
      "i=180, eval_set_loss = 2.1141557664844344\n",
      "i=190, eval_set_loss = 2.113582881984477\n",
      "i=200, eval_set_loss = 2.112622966016399\n",
      "i=210, eval_set_loss = 2.112095799926215\n",
      "i=220, eval_set_loss = 2.112003289743082\n",
      "i=230, eval_set_loss = 2.1118136842276343\n",
      "i=240, eval_set_loss = 2.1117215573502057\n",
      "i=250, eval_set_loss = 2.111524260593301\n",
      "i=260, eval_set_loss = 2.1114601988864474\n",
      "i=270, eval_set_loss = 2.111580616921933\n",
      "Stopping early: curr_loss of 2.111580616921933\n",
      "                                        exceeds compare_loss of 2.1114601988864474\n",
      "Singleton weight = 1.0\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.484818205015985\n",
      "i=10, eval_set_loss = 2.3761553552447494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_6434/1669956703.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=20, eval_set_loss = 2.303860127922712\n",
      "i=30, eval_set_loss = 2.2536317142966262\n",
      "i=40, eval_set_loss = 2.217927898094205\n",
      "i=50, eval_set_loss = 2.192097166114948\n",
      "i=60, eval_set_loss = 2.1727449992792986\n",
      "i=70, eval_set_loss = 2.1584310612089386\n",
      "i=80, eval_set_loss = 2.147478500415672\n",
      "i=90, eval_set_loss = 2.1394513562597557\n",
      "i=100, eval_set_loss = 2.1328129110775857\n",
      "i=110, eval_set_loss = 2.12813924225488\n",
      "i=120, eval_set_loss = 2.1243372268589957\n",
      "i=130, eval_set_loss = 2.1215637151490943\n",
      "i=140, eval_set_loss = 2.119355813370162\n",
      "i=150, eval_set_loss = 2.1177239022246117\n",
      "i=160, eval_set_loss = 2.1166067980181476\n",
      "i=170, eval_set_loss = 2.1155826133915916\n",
      "i=180, eval_set_loss = 2.114822932119884\n",
      "i=190, eval_set_loss = 2.114043416501561\n",
      "i=200, eval_set_loss = 2.1134153282617665\n",
      "i=210, eval_set_loss = 2.113147027244682\n",
      "i=220, eval_set_loss = 2.112774907450477\n",
      "i=230, eval_set_loss = 2.112796887384454\n",
      "Stopping early: curr_loss of 2.112796887384454\n",
      "                                        exceeds compare_loss of 2.112774907450477\n",
      "Singleton weight = 0.0\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.4104459496407142\n",
      "i=20, eval_set_loss = 2.351223723959253\n",
      "i=30, eval_set_loss = 2.3042443680345888\n",
      "i=40, eval_set_loss = 2.2672148867085493\n",
      "i=50, eval_set_loss = 2.238041188107971\n",
      "i=60, eval_set_loss = 2.2148146870950813\n",
      "i=70, eval_set_loss = 2.196033118295173\n",
      "i=80, eval_set_loss = 2.1812834730301263\n",
      "i=90, eval_set_loss = 2.169235800532748\n",
      "i=100, eval_set_loss = 2.159837210103587\n",
      "i=110, eval_set_loss = 2.1521476799389134\n",
      "i=120, eval_set_loss = 2.1458124927934614\n",
      "i=130, eval_set_loss = 2.1402811871407637\n",
      "i=140, eval_set_loss = 2.135918976811574\n",
      "i=150, eval_set_loss = 2.1318234501269013\n",
      "i=160, eval_set_loss = 2.128825144113021\n",
      "i=170, eval_set_loss = 2.126298914700492\n",
      "i=180, eval_set_loss = 2.1253776258395782\n",
      "i=190, eval_set_loss = 2.1235412940498666\n",
      "i=200, eval_set_loss = 2.1218472076268444\n",
      "i=210, eval_set_loss = 2.120488065055029\n",
      "i=220, eval_set_loss = 2.119226446185957\n",
      "i=230, eval_set_loss = 2.11798535550049\n",
      "i=240, eval_set_loss = 2.1167465118326536\n",
      "i=250, eval_set_loss = 2.115718557648894\n",
      "i=260, eval_set_loss = 2.114857056588459\n",
      "i=270, eval_set_loss = 2.113990166576719\n",
      "i=280, eval_set_loss = 2.1132776496535874\n",
      "i=290, eval_set_loss = 2.1123808054955924\n",
      "i=300, eval_set_loss = 2.111812629791291\n",
      "i=310, eval_set_loss = 2.111525859719041\n",
      "i=320, eval_set_loss = 2.111107641748831\n",
      "i=330, eval_set_loss = 2.110560327478317\n",
      "i=340, eval_set_loss = 2.110077462048328\n",
      "i=350, eval_set_loss = 2.1096034431402173\n",
      "i=360, eval_set_loss = 2.109037223383002\n",
      "i=370, eval_set_loss = 2.108587613189426\n",
      "i=380, eval_set_loss = 2.1084437077421594\n",
      "i=390, eval_set_loss = 2.107962886293571\n",
      "i=400, eval_set_loss = 2.107769600321512\n",
      "i=410, eval_set_loss = 2.1076836352204844\n",
      "i=420, eval_set_loss = 2.107497910232125\n",
      "i=430, eval_set_loss = 2.1072838496035713\n",
      "i=440, eval_set_loss = 2.107269202538681\n",
      "i=450, eval_set_loss = 2.1069523112495676\n",
      "i=460, eval_set_loss = 2.1068514588117955\n",
      "i=470, eval_set_loss = 2.1066442280792166\n",
      "i=480, eval_set_loss = 2.1063229418508898\n",
      "i=490, eval_set_loss = 2.106318136602451\n",
      "i=500, eval_set_loss = 2.1062898510751102\n",
      "i=510, eval_set_loss = 2.106009654358477\n",
      "i=520, eval_set_loss = 2.1060092355321003\n",
      "i=530, eval_set_loss = 2.1059412179532164\n",
      "i=540, eval_set_loss = 2.105756686425046\n",
      "i=550, eval_set_loss = 2.105836472193259\n",
      "Stopping early: curr_loss of 2.105836472193259\n",
      "                                        exceeds compare_loss of 2.105756686425046\n",
      "Singleton weight = 0.1\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.3921191703277547\n",
      "i=20, eval_set_loss = 2.323893362468796\n",
      "i=30, eval_set_loss = 2.273382765791901\n",
      "i=40, eval_set_loss = 2.235639641705021\n",
      "i=50, eval_set_loss = 2.207443435470215\n",
      "i=60, eval_set_loss = 2.1856866864835123\n",
      "i=70, eval_set_loss = 2.168696566457691\n",
      "i=80, eval_set_loss = 2.1554601270091336\n",
      "i=90, eval_set_loss = 2.1451381489029426\n",
      "i=100, eval_set_loss = 2.137249224902914\n",
      "i=110, eval_set_loss = 2.1307811429568457\n",
      "i=120, eval_set_loss = 2.1255830019367465\n",
      "i=130, eval_set_loss = 2.121358877746635\n",
      "i=140, eval_set_loss = 2.117949107758782\n",
      "i=150, eval_set_loss = 2.114738651626058\n",
      "i=160, eval_set_loss = 2.1128682705821475\n",
      "i=170, eval_set_loss = 2.110977588419929\n",
      "i=180, eval_set_loss = 2.109546878627164\n",
      "i=190, eval_set_loss = 2.108251215068258\n",
      "i=200, eval_set_loss = 2.1071230903088165\n",
      "i=210, eval_set_loss = 2.106225481143185\n",
      "i=220, eval_set_loss = 2.105511442888432\n",
      "i=230, eval_set_loss = 2.1049711494702588\n",
      "i=240, eval_set_loss = 2.1043472827628773\n",
      "i=250, eval_set_loss = 2.1037065284968777\n",
      "i=260, eval_set_loss = 2.103426149909143\n",
      "i=270, eval_set_loss = 2.1029804264151464\n",
      "i=280, eval_set_loss = 2.102658949147239\n",
      "i=290, eval_set_loss = 2.102410235813712\n",
      "i=300, eval_set_loss = 2.102191661884604\n",
      "i=310, eval_set_loss = 2.1020056529970663\n",
      "i=320, eval_set_loss = 2.1019986709975855\n",
      "i=330, eval_set_loss = 2.1020897938886627\n",
      "Stopping early: curr_loss of 2.1020897938886627\n",
      "                                        exceeds compare_loss of 2.1019986709975855\n",
      "Singleton weight = 0.2\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.391109869859739\n",
      "i=20, eval_set_loss = 2.322575670673539\n",
      "i=30, eval_set_loss = 2.272296276000219\n",
      "i=40, eval_set_loss = 2.2343570870789873\n",
      "i=50, eval_set_loss = 2.206193229919542\n",
      "i=60, eval_set_loss = 2.1846709598849046\n",
      "i=70, eval_set_loss = 2.1676130277300687\n",
      "i=80, eval_set_loss = 2.154383688627897\n",
      "i=90, eval_set_loss = 2.1440391725634886\n",
      "i=100, eval_set_loss = 2.13637524146929\n",
      "i=110, eval_set_loss = 2.12984107475517\n",
      "i=120, eval_set_loss = 2.1247894276883597\n",
      "i=130, eval_set_loss = 2.1205402015086188\n",
      "i=140, eval_set_loss = 2.117090776084902\n",
      "i=150, eval_set_loss = 2.1143103473000724\n",
      "i=160, eval_set_loss = 2.1121481803661695\n",
      "i=170, eval_set_loss = 2.1103407408244217\n",
      "i=180, eval_set_loss = 2.108811668431691\n",
      "i=190, eval_set_loss = 2.1076960743954065\n",
      "i=200, eval_set_loss = 2.1068236259119235\n",
      "i=210, eval_set_loss = 2.105964689822232\n",
      "i=220, eval_set_loss = 2.105247532745529\n",
      "i=230, eval_set_loss = 2.104559536992666\n",
      "i=240, eval_set_loss = 2.1040735687977254\n",
      "i=250, eval_set_loss = 2.103631375770793\n",
      "i=260, eval_set_loss = 2.1033401339276954\n",
      "i=270, eval_set_loss = 2.1029832189471773\n",
      "i=280, eval_set_loss = 2.1026805821708474\n",
      "i=290, eval_set_loss = 2.102595998581237\n",
      "i=300, eval_set_loss = 2.1022182052665834\n",
      "i=310, eval_set_loss = 2.102349872257579\n",
      "Stopping early: curr_loss of 2.102349872257579\n",
      "                                        exceeds compare_loss of 2.1022182052665834\n",
      "Singleton weight = 0.3\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.3900380650608812\n",
      "i=20, eval_set_loss = 2.3211076537440785\n",
      "i=30, eval_set_loss = 2.27078140237238\n",
      "i=40, eval_set_loss = 2.2331533683825024\n",
      "i=50, eval_set_loss = 2.205273521544332\n",
      "i=60, eval_set_loss = 2.1836476139330445\n",
      "i=70, eval_set_loss = 2.166978885479051\n",
      "i=80, eval_set_loss = 2.153937172605844\n",
      "i=90, eval_set_loss = 2.1437935375722956\n",
      "i=100, eval_set_loss = 2.1359516490376858\n",
      "i=110, eval_set_loss = 2.1292823068646256\n",
      "i=120, eval_set_loss = 2.1241436145716546\n",
      "i=130, eval_set_loss = 2.1199061294414236\n",
      "i=140, eval_set_loss = 2.116730303004439\n",
      "i=150, eval_set_loss = 2.113758593927081\n",
      "i=160, eval_set_loss = 2.1118368696286773\n",
      "i=170, eval_set_loss = 2.110231879335687\n",
      "i=180, eval_set_loss = 2.108800364740353\n",
      "i=190, eval_set_loss = 2.1078258429067467\n",
      "i=200, eval_set_loss = 2.106667848033028\n",
      "i=210, eval_set_loss = 2.106034474608858\n",
      "i=220, eval_set_loss = 2.105444338848538\n",
      "i=230, eval_set_loss = 2.1050175061095526\n",
      "i=240, eval_set_loss = 2.104505560533231\n",
      "i=250, eval_set_loss = 2.1042218403115047\n",
      "i=260, eval_set_loss = 2.104283272114784\n",
      "Stopping early: curr_loss of 2.104283272114784\n",
      "                                        exceeds compare_loss of 2.1042218403115047\n",
      "Singleton weight = 0.4\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.3886952659322533\n",
      "i=20, eval_set_loss = 2.319344833576245\n",
      "i=30, eval_set_loss = 2.269023054183205\n",
      "i=40, eval_set_loss = 2.2313132984760364\n",
      "i=50, eval_set_loss = 2.2033825287914457\n",
      "i=60, eval_set_loss = 2.182096955326664\n",
      "i=70, eval_set_loss = 2.165232437760224\n",
      "i=80, eval_set_loss = 2.1522260164094025\n",
      "i=90, eval_set_loss = 2.142326046579403\n",
      "i=100, eval_set_loss = 2.134809417686046\n",
      "i=110, eval_set_loss = 2.1284709612506827\n",
      "i=120, eval_set_loss = 2.123670920971213\n",
      "i=130, eval_set_loss = 2.1197482227608035\n",
      "i=140, eval_set_loss = 2.116496652177537\n",
      "i=150, eval_set_loss = 2.1137068880606478\n",
      "i=160, eval_set_loss = 2.1115964094288215\n",
      "i=170, eval_set_loss = 2.1095863786709224\n",
      "i=180, eval_set_loss = 2.107960136220631\n",
      "i=190, eval_set_loss = 2.1071412021481146\n",
      "i=200, eval_set_loss = 2.106270308406884\n",
      "i=210, eval_set_loss = 2.105794823750233\n",
      "i=220, eval_set_loss = 2.1054429294348456\n",
      "i=230, eval_set_loss = 2.104927166858672\n",
      "i=240, eval_set_loss = 2.1042961259255084\n",
      "i=250, eval_set_loss = 2.103859685984022\n",
      "i=260, eval_set_loss = 2.10345677606777\n",
      "i=270, eval_set_loss = 2.103174260776363\n",
      "i=280, eval_set_loss = 2.102896124844514\n",
      "i=290, eval_set_loss = 2.102668542757441\n",
      "i=300, eval_set_loss = 2.1025045402471645\n",
      "i=310, eval_set_loss = 2.1024276131944\n",
      "i=320, eval_set_loss = 2.1025727259868217\n",
      "Stopping early: curr_loss of 2.1025727259868217\n",
      "                                        exceeds compare_loss of 2.1024276131944\n",
      "Singleton weight = 0.5\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.3872273775946122\n",
      "i=20, eval_set_loss = 2.317405133860964\n",
      "i=30, eval_set_loss = 2.267090063333159\n",
      "i=40, eval_set_loss = 2.22958132436184\n",
      "i=50, eval_set_loss = 2.2016207333394586\n",
      "i=60, eval_set_loss = 2.180560210513389\n",
      "i=70, eval_set_loss = 2.163945674153243\n",
      "i=80, eval_set_loss = 2.151069407646395\n",
      "i=90, eval_set_loss = 2.1413695594205646\n",
      "i=100, eval_set_loss = 2.133821698082843\n",
      "i=110, eval_set_loss = 2.1274902792435673\n",
      "i=120, eval_set_loss = 2.1225879939282017\n",
      "i=130, eval_set_loss = 2.118527677459111\n",
      "i=140, eval_set_loss = 2.1153659867314105\n",
      "i=150, eval_set_loss = 2.1128206856998983\n",
      "i=160, eval_set_loss = 2.11083848016811\n",
      "i=170, eval_set_loss = 2.1090688858179716\n",
      "i=180, eval_set_loss = 2.107502597388044\n",
      "i=190, eval_set_loss = 2.106337779822203\n",
      "i=200, eval_set_loss = 2.105352038431142\n",
      "i=210, eval_set_loss = 2.10493311132924\n",
      "i=220, eval_set_loss = 2.104422900985014\n",
      "i=230, eval_set_loss = 2.103938527576147\n",
      "i=240, eval_set_loss = 2.103289758693745\n",
      "i=250, eval_set_loss = 2.1029392180794075\n",
      "i=260, eval_set_loss = 2.1027043311957088\n",
      "i=270, eval_set_loss = 2.102521389757262\n",
      "i=280, eval_set_loss = 2.1023878841948225\n",
      "i=290, eval_set_loss = 2.102166108501983\n",
      "i=300, eval_set_loss = 2.1018466354212104\n",
      "i=310, eval_set_loss = 2.1016585340985623\n",
      "i=320, eval_set_loss = 2.1015146229781476\n",
      "i=330, eval_set_loss = 2.101694577522127\n",
      "Stopping early: curr_loss of 2.101694577522127\n",
      "                                        exceeds compare_loss of 2.1015146229781476\n",
      "Singleton weight = 0.6\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.385614227295492\n",
      "i=20, eval_set_loss = 2.315210784426787\n",
      "i=30, eval_set_loss = 2.2648420614177747\n",
      "i=40, eval_set_loss = 2.2274504644380153\n",
      "i=50, eval_set_loss = 2.2002768984368353\n",
      "i=60, eval_set_loss = 2.1790659612487704\n",
      "i=70, eval_set_loss = 2.1629052196914236\n",
      "i=80, eval_set_loss = 2.1504564019371717\n",
      "i=90, eval_set_loss = 2.140710724656884\n",
      "i=100, eval_set_loss = 2.1333344758853663\n",
      "i=110, eval_set_loss = 2.1271206843227803\n",
      "i=120, eval_set_loss = 2.1223678674020907\n",
      "i=130, eval_set_loss = 2.1184759652279603\n",
      "i=140, eval_set_loss = 2.1153513725169995\n",
      "i=150, eval_set_loss = 2.1126965407182796\n",
      "i=160, eval_set_loss = 2.1108186444579653\n",
      "i=170, eval_set_loss = 2.1093328724808047\n",
      "i=180, eval_set_loss = 2.10758422939037\n",
      "i=190, eval_set_loss = 2.106749740067139\n",
      "i=200, eval_set_loss = 2.1059070806353497\n",
      "i=210, eval_set_loss = 2.1051008034589604\n",
      "i=220, eval_set_loss = 2.1045698645237163\n",
      "i=230, eval_set_loss = 2.104166875740629\n",
      "i=240, eval_set_loss = 2.1037829286397187\n",
      "i=250, eval_set_loss = 2.1032222033257457\n",
      "i=260, eval_set_loss = 2.103244076428421\n",
      "Stopping early: curr_loss of 2.103244076428421\n",
      "                                        exceeds compare_loss of 2.1032222033257457\n",
      "Singleton weight = 0.7\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.3836476561103357\n",
      "i=20, eval_set_loss = 2.3128136178502277\n",
      "i=30, eval_set_loss = 2.2623206419082806\n",
      "i=40, eval_set_loss = 2.225136043676384\n",
      "i=50, eval_set_loss = 2.1978334720472517\n",
      "i=60, eval_set_loss = 2.177256066454562\n",
      "i=70, eval_set_loss = 2.1611468877386733\n",
      "i=80, eval_set_loss = 2.148785514555906\n",
      "i=90, eval_set_loss = 2.1393257460501656\n",
      "i=100, eval_set_loss = 2.132048708848092\n",
      "i=110, eval_set_loss = 2.1261221236762577\n",
      "i=120, eval_set_loss = 2.1214252845306336\n",
      "i=130, eval_set_loss = 2.1176595803953533\n",
      "i=140, eval_set_loss = 2.1146698377817783\n",
      "i=150, eval_set_loss = 2.1121445217782204\n",
      "i=160, eval_set_loss = 2.1104126032704853\n",
      "i=170, eval_set_loss = 2.108965250909573\n",
      "i=180, eval_set_loss = 2.107542163453552\n",
      "i=190, eval_set_loss = 2.106785771024772\n",
      "i=200, eval_set_loss = 2.106180841426844\n",
      "i=210, eval_set_loss = 2.105563832583974\n",
      "i=220, eval_set_loss = 2.105222013652708\n",
      "i=230, eval_set_loss = 2.1048699049829973\n",
      "i=240, eval_set_loss = 2.104332976219042\n",
      "i=250, eval_set_loss = 2.104192343962689\n",
      "i=260, eval_set_loss = 2.104210464407219\n",
      "Stopping early: curr_loss of 2.104210464407219\n",
      "                                        exceeds compare_loss of 2.104192343962689\n",
      "Singleton weight = 0.8\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.38134702007698\n",
      "i=20, eval_set_loss = 2.3100683741021037\n",
      "i=30, eval_set_loss = 2.259588109824923\n",
      "i=40, eval_set_loss = 2.222677154699478\n",
      "i=50, eval_set_loss = 2.195658283786986\n",
      "i=60, eval_set_loss = 2.174738052440602\n",
      "i=70, eval_set_loss = 2.1590854081768063\n",
      "i=80, eval_set_loss = 2.147008683764044\n",
      "i=90, eval_set_loss = 2.1376444108863173\n",
      "i=100, eval_set_loss = 2.1306898629469897\n",
      "i=110, eval_set_loss = 2.1248644666953913\n",
      "i=120, eval_set_loss = 2.120294720819123\n",
      "i=130, eval_set_loss = 2.116791096582605\n",
      "i=140, eval_set_loss = 2.1141733228352297\n",
      "i=150, eval_set_loss = 2.1117658315663204\n",
      "i=160, eval_set_loss = 2.1101168099258234\n",
      "i=170, eval_set_loss = 2.108586865000136\n",
      "i=180, eval_set_loss = 2.1073668516866406\n",
      "i=190, eval_set_loss = 2.1068967993623913\n",
      "i=200, eval_set_loss = 2.1061251183015655\n",
      "i=210, eval_set_loss = 2.10579088988183\n",
      "i=220, eval_set_loss = 2.1052665064084524\n",
      "i=230, eval_set_loss = 2.104913793300183\n",
      "i=240, eval_set_loss = 2.1046796378729073\n",
      "i=250, eval_set_loss = 2.1043664199227554\n",
      "i=260, eval_set_loss = 2.104627773800476\n",
      "Stopping early: curr_loss of 2.104627773800476\n",
      "                                        exceeds compare_loss of 2.1043664199227554\n",
      "Singleton weight = 0.9\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.378540367157184\n",
      "i=20, eval_set_loss = 2.3068531657369027\n",
      "i=30, eval_set_loss = 2.2567075944501487\n",
      "i=40, eval_set_loss = 2.2201054298996143\n",
      "i=50, eval_set_loss = 2.193335727828057\n",
      "i=60, eval_set_loss = 2.172844713992357\n",
      "i=70, eval_set_loss = 2.1574244369353948\n",
      "i=80, eval_set_loss = 2.145563324115082\n",
      "i=90, eval_set_loss = 2.1363039594245374\n",
      "i=100, eval_set_loss = 2.129780931180111\n",
      "i=110, eval_set_loss = 2.124387862177229\n",
      "i=120, eval_set_loss = 2.1201550588913705\n",
      "i=130, eval_set_loss = 2.116592870071934\n",
      "i=140, eval_set_loss = 2.1140706309907626\n",
      "i=150, eval_set_loss = 2.112049306542626\n",
      "i=160, eval_set_loss = 2.1104532879084865\n",
      "i=170, eval_set_loss = 2.1084672900222876\n",
      "i=180, eval_set_loss = 2.107468997494498\n",
      "i=190, eval_set_loss = 2.1068785181872167\n",
      "i=200, eval_set_loss = 2.106290378431948\n",
      "i=210, eval_set_loss = 2.105777109950364\n",
      "i=220, eval_set_loss = 2.1053633786199164\n",
      "i=230, eval_set_loss = 2.1053525778557405\n",
      "i=240, eval_set_loss = 2.1050985822275807\n",
      "i=250, eval_set_loss = 2.1048182685812\n",
      "i=260, eval_set_loss = 2.104885714357348\n",
      "Stopping early: curr_loss of 2.104885714357348\n",
      "                                        exceeds compare_loss of 2.1048182685812\n",
      "Singleton weight = 1.0\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4849638653409625\n",
      "i=10, eval_set_loss = 2.3754852052772155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_6434/1669956703.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=20, eval_set_loss = 2.3033349864582875\n",
      "i=30, eval_set_loss = 2.252991987147479\n",
      "i=40, eval_set_loss = 2.2165415645966213\n",
      "i=50, eval_set_loss = 2.190256041618133\n",
      "i=60, eval_set_loss = 2.1701526395916253\n",
      "i=70, eval_set_loss = 2.155629190432912\n",
      "i=80, eval_set_loss = 2.1444671310880032\n",
      "i=90, eval_set_loss = 2.1354678127923434\n",
      "i=100, eval_set_loss = 2.128948329334386\n",
      "i=110, eval_set_loss = 2.123502692083623\n",
      "i=120, eval_set_loss = 2.119265540679328\n",
      "i=130, eval_set_loss = 2.1156078450364384\n",
      "i=140, eval_set_loss = 2.112978108191665\n",
      "i=150, eval_set_loss = 2.1111117563165855\n",
      "i=160, eval_set_loss = 2.109887965569854\n",
      "i=170, eval_set_loss = 2.108609223903421\n",
      "i=180, eval_set_loss = 2.1076921088996112\n",
      "i=190, eval_set_loss = 2.107318992554829\n",
      "i=200, eval_set_loss = 2.106813587784542\n",
      "i=210, eval_set_loss = 2.106681633937159\n",
      "i=220, eval_set_loss = 2.106517014110933\n",
      "i=230, eval_set_loss = 2.1063951161881573\n",
      "i=240, eval_set_loss = 2.1062153004826936\n",
      "i=250, eval_set_loss = 2.106108792437601\n",
      "i=260, eval_set_loss = 2.1060306046690855\n",
      "i=270, eval_set_loss = 2.106011755040965\n",
      "i=280, eval_set_loss = 2.106200912248736\n",
      "Stopping early: curr_loss of 2.106200912248736\n",
      "                                        exceeds compare_loss of 2.106011755040965\n",
      "Singleton weight = 0.0\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.4105645079689926\n",
      "i=20, eval_set_loss = 2.351836971067319\n",
      "i=30, eval_set_loss = 2.305233702509887\n",
      "i=40, eval_set_loss = 2.268538509512527\n",
      "i=50, eval_set_loss = 2.2402585633795966\n",
      "i=60, eval_set_loss = 2.2175286413422506\n",
      "i=70, eval_set_loss = 2.2000577398735333\n",
      "i=80, eval_set_loss = 2.186330787215885\n",
      "i=90, eval_set_loss = 2.1751435476181866\n",
      "i=100, eval_set_loss = 2.165669510464745\n",
      "i=110, eval_set_loss = 2.158064308585831\n",
      "i=120, eval_set_loss = 2.151846512262083\n",
      "i=130, eval_set_loss = 2.1459821985643064\n",
      "i=140, eval_set_loss = 2.141582775079493\n",
      "i=150, eval_set_loss = 2.1377359742862323\n",
      "i=160, eval_set_loss = 2.134453322601973\n",
      "i=170, eval_set_loss = 2.1315809844150397\n",
      "i=180, eval_set_loss = 2.1292131584729894\n",
      "i=190, eval_set_loss = 2.126917297418584\n",
      "i=200, eval_set_loss = 2.1248677063394896\n",
      "i=210, eval_set_loss = 2.123177726873042\n",
      "i=220, eval_set_loss = 2.121545307185064\n",
      "i=230, eval_set_loss = 2.1201797481602127\n",
      "i=240, eval_set_loss = 2.1189664494076044\n",
      "i=250, eval_set_loss = 2.117861328664693\n",
      "i=260, eval_set_loss = 2.1168992304471934\n",
      "i=270, eval_set_loss = 2.1168390487922153\n",
      "i=280, eval_set_loss = 2.1163313479873294\n",
      "i=290, eval_set_loss = 2.115420717227236\n",
      "i=300, eval_set_loss = 2.116736027944526\n",
      "Stopping early: curr_loss of 2.116736027944526\n",
      "                                        exceeds compare_loss of 2.115420717227236\n",
      "Singleton weight = 0.1\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.3932121219205977\n",
      "i=20, eval_set_loss = 2.3261128302194396\n",
      "i=30, eval_set_loss = 2.2765754840402885\n",
      "i=40, eval_set_loss = 2.2384801171547957\n",
      "i=50, eval_set_loss = 2.20958362842085\n",
      "i=60, eval_set_loss = 2.187725140693981\n",
      "i=70, eval_set_loss = 2.17126925959367\n",
      "i=80, eval_set_loss = 2.159021161286861\n",
      "i=90, eval_set_loss = 2.14920940970541\n",
      "i=100, eval_set_loss = 2.141107515336917\n",
      "i=110, eval_set_loss = 2.134653705196153\n",
      "i=120, eval_set_loss = 2.129806287227367\n",
      "i=130, eval_set_loss = 2.124990974714229\n",
      "i=140, eval_set_loss = 2.1213688010313554\n",
      "i=150, eval_set_loss = 2.1186206673663146\n",
      "i=160, eval_set_loss = 2.116112833757975\n",
      "i=170, eval_set_loss = 2.1140918012337666\n",
      "i=180, eval_set_loss = 2.1122656717124797\n",
      "i=190, eval_set_loss = 2.1109092516986303\n",
      "i=200, eval_set_loss = 2.109861187484185\n",
      "i=210, eval_set_loss = 2.108545002923374\n",
      "i=220, eval_set_loss = 2.1076218257799963\n",
      "i=230, eval_set_loss = 2.1068266111493963\n",
      "i=240, eval_set_loss = 2.106094833140057\n",
      "i=250, eval_set_loss = 2.105638202848392\n",
      "i=260, eval_set_loss = 2.1052161775031983\n",
      "i=270, eval_set_loss = 2.1046025441090728\n",
      "i=280, eval_set_loss = 2.1045378640726327\n",
      "i=290, eval_set_loss = 2.104165014282328\n",
      "i=300, eval_set_loss = 2.1040045221172594\n",
      "i=310, eval_set_loss = 2.1038575491963534\n",
      "i=320, eval_set_loss = 2.10378861321042\n",
      "i=330, eval_set_loss = 2.1037775814319737\n",
      "i=340, eval_set_loss = 2.103682169615524\n",
      "i=350, eval_set_loss = 2.1037239580112836\n",
      "Stopping early: curr_loss of 2.1037239580112836\n",
      "                                        exceeds compare_loss of 2.103682169615524\n",
      "Singleton weight = 0.2\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.3922311303049626\n",
      "i=20, eval_set_loss = 2.324789236797748\n",
      "i=30, eval_set_loss = 2.2751442538993683\n",
      "i=40, eval_set_loss = 2.237065777582285\n",
      "i=50, eval_set_loss = 2.208804341890742\n",
      "i=60, eval_set_loss = 2.187058967830429\n",
      "i=70, eval_set_loss = 2.1705442274756126\n",
      "i=80, eval_set_loss = 2.1579760918197577\n",
      "i=90, eval_set_loss = 2.1477575652234826\n",
      "i=100, eval_set_loss = 2.1396565904868665\n",
      "i=110, eval_set_loss = 2.13324008606656\n",
      "i=120, eval_set_loss = 2.1286870715761594\n",
      "i=130, eval_set_loss = 2.123829461897011\n",
      "i=140, eval_set_loss = 2.1205967921800215\n",
      "i=150, eval_set_loss = 2.1180576782928364\n",
      "i=160, eval_set_loss = 2.1157314105758407\n",
      "i=170, eval_set_loss = 2.113774438017179\n",
      "i=180, eval_set_loss = 2.112059299058173\n",
      "i=190, eval_set_loss = 2.110347700291324\n",
      "i=200, eval_set_loss = 2.1094306408285477\n",
      "i=210, eval_set_loss = 2.1085725522672196\n",
      "i=220, eval_set_loss = 2.1080400011774056\n",
      "i=230, eval_set_loss = 2.107347145405345\n",
      "i=240, eval_set_loss = 2.106643439009921\n",
      "i=250, eval_set_loss = 2.106119142498686\n",
      "i=260, eval_set_loss = 2.105415953375498\n",
      "i=270, eval_set_loss = 2.1052279809732712\n",
      "i=280, eval_set_loss = 2.1052371461203196\n",
      "Stopping early: curr_loss of 2.1052371461203196\n",
      "                                        exceeds compare_loss of 2.1052279809732712\n",
      "Singleton weight = 0.3\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.3910610098265836\n",
      "i=20, eval_set_loss = 2.3232078361083435\n",
      "i=30, eval_set_loss = 2.273481856248348\n",
      "i=40, eval_set_loss = 2.235435576073405\n",
      "i=50, eval_set_loss = 2.207116508146586\n",
      "i=60, eval_set_loss = 2.18568605486788\n",
      "i=70, eval_set_loss = 2.169419980066308\n",
      "i=80, eval_set_loss = 2.1571799064102226\n",
      "i=90, eval_set_loss = 2.1471477129106153\n",
      "i=100, eval_set_loss = 2.139084245991328\n",
      "i=110, eval_set_loss = 2.132875813712297\n",
      "i=120, eval_set_loss = 2.12779196905864\n",
      "i=130, eval_set_loss = 2.12298439752728\n",
      "i=140, eval_set_loss = 2.1200487994766126\n",
      "i=150, eval_set_loss = 2.1174224177850514\n",
      "i=160, eval_set_loss = 2.115282410291188\n",
      "i=170, eval_set_loss = 2.113459229294132\n",
      "i=180, eval_set_loss = 2.1119116654682655\n",
      "i=190, eval_set_loss = 2.1103636141983384\n",
      "i=200, eval_set_loss = 2.1093120268186416\n",
      "i=210, eval_set_loss = 2.1082239298361856\n",
      "i=220, eval_set_loss = 2.107509688936265\n",
      "i=230, eval_set_loss = 2.1068071755931697\n",
      "i=240, eval_set_loss = 2.1062490655895885\n",
      "i=250, eval_set_loss = 2.105831312676012\n",
      "i=260, eval_set_loss = 2.1054153266759013\n",
      "i=270, eval_set_loss = 2.105110016264153\n",
      "i=280, eval_set_loss = 2.1048140987453747\n",
      "i=290, eval_set_loss = 2.1048102934495785\n",
      "i=300, eval_set_loss = 2.1046005742163194\n",
      "i=310, eval_set_loss = 2.104631817049766\n",
      "Stopping early: curr_loss of 2.104631817049766\n",
      "                                        exceeds compare_loss of 2.1046005742163194\n",
      "Singleton weight = 0.4\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.3898846213975626\n",
      "i=20, eval_set_loss = 2.3217619193369172\n",
      "i=30, eval_set_loss = 2.2721802200090497\n",
      "i=40, eval_set_loss = 2.2339772143335526\n",
      "i=50, eval_set_loss = 2.205558375358545\n",
      "i=60, eval_set_loss = 2.1842668394919595\n",
      "i=70, eval_set_loss = 2.1681986731334932\n",
      "i=80, eval_set_loss = 2.1563121652611597\n",
      "i=90, eval_set_loss = 2.1462894635500165\n",
      "i=100, eval_set_loss = 2.1383510784548276\n",
      "i=110, eval_set_loss = 2.1321088455547637\n",
      "i=120, eval_set_loss = 2.12765611729791\n",
      "i=130, eval_set_loss = 2.1232826262513846\n",
      "i=140, eval_set_loss = 2.120065734685089\n",
      "i=150, eval_set_loss = 2.117484730604624\n",
      "i=160, eval_set_loss = 2.1155335206754833\n",
      "i=170, eval_set_loss = 2.1137501072387503\n",
      "i=180, eval_set_loss = 2.1124575520638955\n",
      "i=190, eval_set_loss = 2.1110377433456553\n",
      "i=200, eval_set_loss = 2.110028063548668\n",
      "i=210, eval_set_loss = 2.109102891479904\n",
      "i=220, eval_set_loss = 2.108372980256216\n",
      "i=230, eval_set_loss = 2.10763994234445\n",
      "i=240, eval_set_loss = 2.107209078103885\n",
      "i=250, eval_set_loss = 2.10677053705676\n",
      "i=260, eval_set_loss = 2.1062681712822036\n",
      "i=270, eval_set_loss = 2.1058973281584796\n",
      "i=280, eval_set_loss = 2.1058792710101266\n",
      "i=290, eval_set_loss = 2.105791381585026\n",
      "i=300, eval_set_loss = 2.1059014464816386\n",
      "Stopping early: curr_loss of 2.1059014464816386\n",
      "                                        exceeds compare_loss of 2.105791381585026\n",
      "Singleton weight = 0.5\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.3885981422692817\n",
      "i=20, eval_set_loss = 2.320073775702386\n",
      "i=30, eval_set_loss = 2.2696062032551234\n",
      "i=40, eval_set_loss = 2.23169338238255\n",
      "i=50, eval_set_loss = 2.203883129672257\n",
      "i=60, eval_set_loss = 2.1822958586647525\n",
      "i=70, eval_set_loss = 2.1664947628169595\n",
      "i=80, eval_set_loss = 2.1545435479056794\n",
      "i=90, eval_set_loss = 2.1446375173471606\n",
      "i=100, eval_set_loss = 2.137070128346719\n",
      "i=110, eval_set_loss = 2.130695847763423\n",
      "i=120, eval_set_loss = 2.1256546700278953\n",
      "i=130, eval_set_loss = 2.1211907217434294\n",
      "i=140, eval_set_loss = 2.11829445305822\n",
      "i=150, eval_set_loss = 2.116180498123928\n",
      "i=160, eval_set_loss = 2.1141682203807717\n",
      "i=170, eval_set_loss = 2.1124331241459444\n",
      "i=180, eval_set_loss = 2.111045987861941\n",
      "i=190, eval_set_loss = 2.109717685110202\n",
      "i=200, eval_set_loss = 2.108713874214889\n",
      "i=210, eval_set_loss = 2.1078250760134494\n",
      "i=220, eval_set_loss = 2.1070723055518656\n",
      "i=230, eval_set_loss = 2.106424364173068\n",
      "i=240, eval_set_loss = 2.106103364896321\n",
      "i=250, eval_set_loss = 2.105602647307708\n",
      "i=260, eval_set_loss = 2.1053201651588593\n",
      "i=270, eval_set_loss = 2.1049565742445187\n",
      "i=280, eval_set_loss = 2.104961097894581\n",
      "Stopping early: curr_loss of 2.104961097894581\n",
      "                                        exceeds compare_loss of 2.1049565742445187\n",
      "Singleton weight = 0.6\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.3869680765256525\n",
      "i=20, eval_set_loss = 2.3179840108075096\n",
      "i=30, eval_set_loss = 2.2675991324436153\n",
      "i=40, eval_set_loss = 2.230478375679007\n",
      "i=50, eval_set_loss = 2.202365889193234\n",
      "i=60, eval_set_loss = 2.1812512020241193\n",
      "i=70, eval_set_loss = 2.165100812621251\n",
      "i=80, eval_set_loss = 2.1527678958689207\n",
      "i=90, eval_set_loss = 2.143439862319917\n",
      "i=100, eval_set_loss = 2.1356116647001486\n",
      "i=110, eval_set_loss = 2.1297548720698107\n",
      "i=120, eval_set_loss = 2.125486935435214\n",
      "i=130, eval_set_loss = 2.1209765008216475\n",
      "i=140, eval_set_loss = 2.117983003155954\n",
      "i=150, eval_set_loss = 2.11598931544266\n",
      "i=160, eval_set_loss = 2.114141533054517\n",
      "i=170, eval_set_loss = 2.1124976623387104\n",
      "i=180, eval_set_loss = 2.111145747973059\n",
      "i=190, eval_set_loss = 2.109896181900628\n",
      "i=200, eval_set_loss = 2.1091869784976587\n",
      "i=210, eval_set_loss = 2.108234745660667\n",
      "i=220, eval_set_loss = 2.1081195836953595\n",
      "i=230, eval_set_loss = 2.1073049508518835\n",
      "i=240, eval_set_loss = 2.1072108420021105\n",
      "i=250, eval_set_loss = 2.106907070542076\n",
      "i=260, eval_set_loss = 2.106500715254081\n",
      "i=270, eval_set_loss = 2.1061255953253273\n",
      "i=280, eval_set_loss = 2.1063901819983104\n",
      "Stopping early: curr_loss of 2.1063901819983104\n",
      "                                        exceeds compare_loss of 2.1061255953253273\n",
      "Singleton weight = 0.7\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.38516313577241\n",
      "i=20, eval_set_loss = 2.316026959382168\n",
      "i=30, eval_set_loss = 2.2653681001594412\n",
      "i=40, eval_set_loss = 2.2280491748144757\n",
      "i=50, eval_set_loss = 2.2000590760200693\n",
      "i=60, eval_set_loss = 2.1795389334186686\n",
      "i=70, eval_set_loss = 2.1642122266233144\n",
      "i=80, eval_set_loss = 2.1523964639732833\n",
      "i=90, eval_set_loss = 2.1434967638958815\n",
      "i=100, eval_set_loss = 2.135664865636575\n",
      "i=110, eval_set_loss = 2.1299560848182346\n",
      "i=120, eval_set_loss = 2.1257720745447255\n",
      "i=130, eval_set_loss = 2.1215898334247854\n",
      "i=140, eval_set_loss = 2.1182393743468646\n",
      "i=150, eval_set_loss = 2.116293399748949\n",
      "i=160, eval_set_loss = 2.114429159337261\n",
      "i=170, eval_set_loss = 2.1129276050699333\n",
      "i=180, eval_set_loss = 2.1114518625709877\n",
      "i=190, eval_set_loss = 2.1105273333786694\n",
      "i=200, eval_set_loss = 2.1094800669992857\n",
      "i=210, eval_set_loss = 2.1089168090728267\n",
      "i=220, eval_set_loss = 2.1082367305392804\n",
      "i=230, eval_set_loss = 2.1075372100395704\n",
      "i=240, eval_set_loss = 2.1074969182940624\n",
      "i=250, eval_set_loss = 2.1073902846836665\n",
      "i=260, eval_set_loss = 2.1072405172574125\n",
      "i=270, eval_set_loss = 2.1070513723138204\n",
      "i=280, eval_set_loss = 2.106882054560853\n",
      "i=290, eval_set_loss = 2.106896008022271\n",
      "Stopping early: curr_loss of 2.106896008022271\n",
      "                                        exceeds compare_loss of 2.106882054560853\n",
      "Singleton weight = 0.8\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.3830078306221445\n",
      "i=20, eval_set_loss = 2.31325888962522\n",
      "i=30, eval_set_loss = 2.2625465310203405\n",
      "i=40, eval_set_loss = 2.2259421629884617\n",
      "i=50, eval_set_loss = 2.1982609695106707\n",
      "i=60, eval_set_loss = 2.177805705986612\n",
      "i=70, eval_set_loss = 2.162714982922424\n",
      "i=80, eval_set_loss = 2.151020599127568\n",
      "i=90, eval_set_loss = 2.1421769664481585\n",
      "i=100, eval_set_loss = 2.1345024657952085\n",
      "i=110, eval_set_loss = 2.129068608343054\n",
      "i=120, eval_set_loss = 2.125154083141448\n",
      "i=130, eval_set_loss = 2.121117611398274\n",
      "i=140, eval_set_loss = 2.1182712271847266\n",
      "i=150, eval_set_loss = 2.116042536373708\n",
      "i=160, eval_set_loss = 2.1141798021814733\n",
      "i=170, eval_set_loss = 2.1128070922006374\n",
      "i=180, eval_set_loss = 2.1114899677838928\n",
      "i=190, eval_set_loss = 2.1103991516427594\n",
      "i=200, eval_set_loss = 2.1095672015696003\n",
      "i=210, eval_set_loss = 2.1089051644368912\n",
      "i=220, eval_set_loss = 2.1084337401540876\n",
      "i=230, eval_set_loss = 2.1078666081078183\n",
      "i=240, eval_set_loss = 2.107542699123192\n",
      "i=250, eval_set_loss = 2.1076835780884196\n",
      "Stopping early: curr_loss of 2.1076835780884196\n",
      "                                        exceeds compare_loss of 2.107542699123192\n",
      "Singleton weight = 0.9\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.3806029062110525\n",
      "i=20, eval_set_loss = 2.310292594637872\n",
      "i=30, eval_set_loss = 2.259520120024418\n",
      "i=40, eval_set_loss = 2.2230771181278013\n",
      "i=50, eval_set_loss = 2.1957379444047627\n",
      "i=60, eval_set_loss = 2.175806214024977\n",
      "i=70, eval_set_loss = 2.1606823077716273\n",
      "i=80, eval_set_loss = 2.1496526445480804\n",
      "i=90, eval_set_loss = 2.1407372536729543\n",
      "i=100, eval_set_loss = 2.133530511614935\n",
      "i=110, eval_set_loss = 2.128153783109394\n",
      "i=120, eval_set_loss = 2.1239156892707496\n",
      "i=130, eval_set_loss = 2.120022691156902\n",
      "i=140, eval_set_loss = 2.1171055928501867\n",
      "i=150, eval_set_loss = 2.114916509494138\n",
      "i=160, eval_set_loss = 2.11287845943868\n",
      "i=170, eval_set_loss = 2.1114460125956516\n",
      "i=180, eval_set_loss = 2.110303622107097\n",
      "i=190, eval_set_loss = 2.1095791310700935\n",
      "i=200, eval_set_loss = 2.108383050080985\n",
      "i=210, eval_set_loss = 2.107793878680189\n",
      "i=220, eval_set_loss = 2.10739649333068\n",
      "i=230, eval_set_loss = 2.106780276815019\n",
      "i=240, eval_set_loss = 2.106617132056347\n",
      "i=250, eval_set_loss = 2.106705605663943\n",
      "Stopping early: curr_loss of 2.106705605663943\n",
      "                                        exceeds compare_loss of 2.106617132056347\n",
      "Singleton weight = 1.0\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.4847572714983004\n",
      "i=10, eval_set_loss = 2.3773981890629847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_6434/1669956703.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=20, eval_set_loss = 2.3065067818471405\n",
      "i=30, eval_set_loss = 2.2559505306892964\n",
      "i=40, eval_set_loss = 2.219096711184944\n",
      "i=50, eval_set_loss = 2.192512390719292\n",
      "i=60, eval_set_loss = 2.172799394482729\n",
      "i=70, eval_set_loss = 2.1584678697135247\n",
      "i=80, eval_set_loss = 2.1474488111490837\n",
      "i=90, eval_set_loss = 2.1381115699026876\n",
      "i=100, eval_set_loss = 2.1310960882593672\n",
      "i=110, eval_set_loss = 2.1258784990344743\n",
      "i=120, eval_set_loss = 2.1219982914639703\n",
      "i=130, eval_set_loss = 2.118468581488938\n",
      "i=140, eval_set_loss = 2.115794130727427\n",
      "i=150, eval_set_loss = 2.1138188644227123\n",
      "i=160, eval_set_loss = 2.1124413093115604\n",
      "i=170, eval_set_loss = 2.1112297095800794\n",
      "i=180, eval_set_loss = 2.1100534120193655\n",
      "i=190, eval_set_loss = 2.109221006918039\n",
      "i=200, eval_set_loss = 2.108217392548732\n",
      "i=210, eval_set_loss = 2.107966733841714\n",
      "i=220, eval_set_loss = 2.107585497052196\n",
      "i=230, eval_set_loss = 2.1071142702655328\n",
      "i=240, eval_set_loss = 2.107268325651782\n",
      "Stopping early: curr_loss of 2.107268325651782\n",
      "                                        exceeds compare_loss of 2.1071142702655328\n",
      "Singleton weight = 0.0\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.413053554645173\n",
      "i=20, eval_set_loss = 2.355510294272249\n",
      "i=30, eval_set_loss = 2.3103436496595315\n",
      "i=40, eval_set_loss = 2.2741778699513\n",
      "i=50, eval_set_loss = 2.2450643753794495\n",
      "i=60, eval_set_loss = 2.222454252933299\n",
      "i=70, eval_set_loss = 2.204552510588576\n",
      "i=80, eval_set_loss = 2.189982657612483\n",
      "i=90, eval_set_loss = 2.1784180425613426\n",
      "i=100, eval_set_loss = 2.168868660641159\n",
      "i=110, eval_set_loss = 2.160760125857967\n",
      "i=120, eval_set_loss = 2.1543949502373136\n",
      "i=130, eval_set_loss = 2.1489055879027954\n",
      "i=140, eval_set_loss = 2.144478989853018\n",
      "i=150, eval_set_loss = 2.140479928189901\n",
      "i=160, eval_set_loss = 2.137186619886225\n",
      "i=170, eval_set_loss = 2.1344632228726086\n",
      "i=180, eval_set_loss = 2.1319873034614583\n",
      "i=190, eval_set_loss = 2.129823860613573\n",
      "i=200, eval_set_loss = 2.127893294761316\n",
      "i=210, eval_set_loss = 2.126298434481875\n",
      "i=220, eval_set_loss = 2.124765943385615\n",
      "i=230, eval_set_loss = 2.1234378041555564\n",
      "i=240, eval_set_loss = 2.122317807660849\n",
      "i=250, eval_set_loss = 2.1215403754215045\n",
      "i=260, eval_set_loss = 2.1207063713040197\n",
      "i=270, eval_set_loss = 2.12008153752992\n",
      "i=280, eval_set_loss = 2.1192779952950884\n",
      "i=290, eval_set_loss = 2.118541171565443\n",
      "i=300, eval_set_loss = 2.1179647182793992\n",
      "i=310, eval_set_loss = 2.117413487850924\n",
      "i=320, eval_set_loss = 2.116877636079532\n",
      "i=330, eval_set_loss = 2.1164353521551513\n",
      "i=340, eval_set_loss = 2.116068821603995\n",
      "i=350, eval_set_loss = 2.1156218193139584\n",
      "i=360, eval_set_loss = 2.1152363318224356\n",
      "i=370, eval_set_loss = 2.1147628153301063\n",
      "i=380, eval_set_loss = 2.1144506075465896\n",
      "i=390, eval_set_loss = 2.114293496692376\n",
      "i=400, eval_set_loss = 2.114238276882769\n",
      "i=410, eval_set_loss = 2.1140259465639106\n",
      "i=420, eval_set_loss = 2.113937375215762\n",
      "i=430, eval_set_loss = 2.1138037265599285\n",
      "i=440, eval_set_loss = 2.11360326034326\n",
      "i=450, eval_set_loss = 2.113530531559092\n",
      "i=460, eval_set_loss = 2.1135665932228767\n",
      "Stopping early: curr_loss of 2.1135665932228767\n",
      "                                        exceeds compare_loss of 2.113530531559092\n",
      "Singleton weight = 0.1\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.3948070899197367\n",
      "i=20, eval_set_loss = 2.3286018959742365\n",
      "i=30, eval_set_loss = 2.279313755485456\n",
      "i=40, eval_set_loss = 2.242362727491435\n",
      "i=50, eval_set_loss = 2.213911391183787\n",
      "i=60, eval_set_loss = 2.192655240433661\n",
      "i=70, eval_set_loss = 2.176267838169763\n",
      "i=80, eval_set_loss = 2.1633547145269167\n",
      "i=90, eval_set_loss = 2.153317024140437\n",
      "i=100, eval_set_loss = 2.1452907511730004\n",
      "i=110, eval_set_loss = 2.138690507619211\n",
      "i=120, eval_set_loss = 2.1336932982215906\n",
      "i=130, eval_set_loss = 2.1298822211195088\n",
      "i=140, eval_set_loss = 2.127010146609252\n",
      "i=150, eval_set_loss = 2.1241663734265632\n",
      "i=160, eval_set_loss = 2.122006913413908\n",
      "i=170, eval_set_loss = 2.1206046174388695\n",
      "i=180, eval_set_loss = 2.119353483830443\n",
      "i=190, eval_set_loss = 2.118005762102771\n",
      "i=200, eval_set_loss = 2.117020987697886\n",
      "i=210, eval_set_loss = 2.11617982075355\n",
      "i=220, eval_set_loss = 2.115470006337057\n",
      "i=230, eval_set_loss = 2.11493655137227\n",
      "i=240, eval_set_loss = 2.1143441671268715\n",
      "i=250, eval_set_loss = 2.1140918131921653\n",
      "i=260, eval_set_loss = 2.113759039866981\n",
      "i=270, eval_set_loss = 2.1134372347525883\n",
      "i=280, eval_set_loss = 2.113251007924798\n",
      "i=290, eval_set_loss = 2.11308822230907\n",
      "i=300, eval_set_loss = 2.1130216000721522\n",
      "i=310, eval_set_loss = 2.1129298660988276\n",
      "i=320, eval_set_loss = 2.1129406330128915\n",
      "Stopping early: curr_loss of 2.1129406330128915\n",
      "                                        exceeds compare_loss of 2.1129298660988276\n",
      "Singleton weight = 0.2\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.3939260384673866\n",
      "i=20, eval_set_loss = 2.3273159816068474\n",
      "i=30, eval_set_loss = 2.277932585817628\n",
      "i=40, eval_set_loss = 2.2410052319848974\n",
      "i=50, eval_set_loss = 2.21255551609049\n",
      "i=60, eval_set_loss = 2.191343572339299\n",
      "i=70, eval_set_loss = 2.1751202163366012\n",
      "i=80, eval_set_loss = 2.162376624338577\n",
      "i=90, eval_set_loss = 2.152158160757272\n",
      "i=100, eval_set_loss = 2.1438102141461366\n",
      "i=110, eval_set_loss = 2.137585630299705\n",
      "i=120, eval_set_loss = 2.132688072089698\n",
      "i=130, eval_set_loss = 2.128824343525091\n",
      "i=140, eval_set_loss = 2.126145851943007\n",
      "i=150, eval_set_loss = 2.123462105024728\n",
      "i=160, eval_set_loss = 2.121319104847491\n",
      "i=170, eval_set_loss = 2.1199653975767605\n",
      "i=180, eval_set_loss = 2.118598130548903\n",
      "i=190, eval_set_loss = 2.117144975547281\n",
      "i=200, eval_set_loss = 2.116182888520083\n",
      "i=210, eval_set_loss = 2.1153053348650164\n",
      "i=220, eval_set_loss = 2.114617789854385\n",
      "i=230, eval_set_loss = 2.114301898708913\n",
      "i=240, eval_set_loss = 2.1137814245529816\n",
      "i=250, eval_set_loss = 2.1133962640171973\n",
      "i=260, eval_set_loss = 2.1131320172364556\n",
      "i=270, eval_set_loss = 2.112927906177175\n",
      "i=280, eval_set_loss = 2.112977420641903\n",
      "Stopping early: curr_loss of 2.112977420641903\n",
      "                                        exceeds compare_loss of 2.112927906177175\n",
      "Singleton weight = 0.3\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.392772071290881\n",
      "i=20, eval_set_loss = 2.325767092060696\n",
      "i=30, eval_set_loss = 2.276338862215535\n",
      "i=40, eval_set_loss = 2.239317508661955\n",
      "i=50, eval_set_loss = 2.211282227376425\n",
      "i=60, eval_set_loss = 2.1903070029725393\n",
      "i=70, eval_set_loss = 2.173863296621228\n",
      "i=80, eval_set_loss = 2.1610916238756404\n",
      "i=90, eval_set_loss = 2.151470201841305\n",
      "i=100, eval_set_loss = 2.1435908439303777\n",
      "i=110, eval_set_loss = 2.137206786084777\n",
      "i=120, eval_set_loss = 2.132732912642696\n",
      "i=130, eval_set_loss = 2.128910426266434\n",
      "i=140, eval_set_loss = 2.1261022350296015\n",
      "i=150, eval_set_loss = 2.1235139616554055\n",
      "i=160, eval_set_loss = 2.1214578644134883\n",
      "i=170, eval_set_loss = 2.1199904233255955\n",
      "i=180, eval_set_loss = 2.1184405200831593\n",
      "i=190, eval_set_loss = 2.1171465866255073\n",
      "i=200, eval_set_loss = 2.1164419445432294\n",
      "i=210, eval_set_loss = 2.1154995328017168\n",
      "i=220, eval_set_loss = 2.1147991737926874\n",
      "i=230, eval_set_loss = 2.114322215968605\n",
      "i=240, eval_set_loss = 2.113929266940129\n",
      "i=250, eval_set_loss = 2.113585372521007\n",
      "i=260, eval_set_loss = 2.113458022686675\n",
      "i=270, eval_set_loss = 2.1131089511722276\n",
      "i=280, eval_set_loss = 2.113188385565924\n",
      "Stopping early: curr_loss of 2.113188385565924\n",
      "                                        exceeds compare_loss of 2.1131089511722276\n",
      "Singleton weight = 0.4\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.391385260400473\n",
      "i=20, eval_set_loss = 2.323919519557183\n",
      "i=30, eval_set_loss = 2.2745524720800216\n",
      "i=40, eval_set_loss = 2.2375573017610813\n",
      "i=50, eval_set_loss = 2.2100885746505696\n",
      "i=60, eval_set_loss = 2.1892550194959046\n",
      "i=70, eval_set_loss = 2.1731950020948694\n",
      "i=80, eval_set_loss = 2.160453011175577\n",
      "i=90, eval_set_loss = 2.1507788787696946\n",
      "i=100, eval_set_loss = 2.1431355405566896\n",
      "i=110, eval_set_loss = 2.136947633416289\n",
      "i=120, eval_set_loss = 2.1324976461595444\n",
      "i=130, eval_set_loss = 2.128658645909772\n",
      "i=140, eval_set_loss = 2.12588705115877\n",
      "i=150, eval_set_loss = 2.123118417874838\n",
      "i=160, eval_set_loss = 2.1210923055680184\n",
      "i=170, eval_set_loss = 2.119539177963403\n",
      "i=180, eval_set_loss = 2.11866410573913\n",
      "i=190, eval_set_loss = 2.117432541970948\n",
      "i=200, eval_set_loss = 2.1167866115626075\n",
      "i=210, eval_set_loss = 2.1161793540236706\n",
      "i=220, eval_set_loss = 2.1153795689460706\n",
      "i=230, eval_set_loss = 2.1147773805708385\n",
      "i=240, eval_set_loss = 2.1143935473016793\n",
      "i=250, eval_set_loss = 2.113951238467727\n",
      "i=260, eval_set_loss = 2.1138528304631867\n",
      "i=270, eval_set_loss = 2.113496932978655\n",
      "i=280, eval_set_loss = 2.1135197022648686\n",
      "Stopping early: curr_loss of 2.1135197022648686\n",
      "                                        exceeds compare_loss of 2.113496932978655\n",
      "Singleton weight = 0.5\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.389997708540121\n",
      "i=20, eval_set_loss = 2.3220310125917365\n",
      "i=30, eval_set_loss = 2.2726193565105213\n",
      "i=40, eval_set_loss = 2.2357050425488887\n",
      "i=50, eval_set_loss = 2.2083286450669726\n",
      "i=60, eval_set_loss = 2.1873296356237075\n",
      "i=70, eval_set_loss = 2.171540899412284\n",
      "i=80, eval_set_loss = 2.1590580827018933\n",
      "i=90, eval_set_loss = 2.149573307370681\n",
      "i=100, eval_set_loss = 2.142130423435849\n",
      "i=110, eval_set_loss = 2.135997751965505\n",
      "i=120, eval_set_loss = 2.131428684525558\n",
      "i=130, eval_set_loss = 2.127814485000421\n",
      "i=140, eval_set_loss = 2.125062198073993\n",
      "i=150, eval_set_loss = 2.1228453264264937\n",
      "i=160, eval_set_loss = 2.1209054119812887\n",
      "i=170, eval_set_loss = 2.119773358458863\n",
      "i=180, eval_set_loss = 2.11854437058476\n",
      "i=190, eval_set_loss = 2.117558291564824\n",
      "i=200, eval_set_loss = 2.1167271042439277\n",
      "i=210, eval_set_loss = 2.1159237316755948\n",
      "i=220, eval_set_loss = 2.1152426582707577\n",
      "i=230, eval_set_loss = 2.114871180599393\n",
      "i=240, eval_set_loss = 2.1144874741575848\n",
      "i=250, eval_set_loss = 2.1140100119021206\n",
      "i=260, eval_set_loss = 2.113898587892224\n",
      "i=270, eval_set_loss = 2.113548331467644\n",
      "i=280, eval_set_loss = 2.1135113760777124\n",
      "i=290, eval_set_loss = 2.1135762652572403\n",
      "Stopping early: curr_loss of 2.1135762652572403\n",
      "                                        exceeds compare_loss of 2.1135113760777124\n",
      "Singleton weight = 0.6\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.3883595294511135\n",
      "i=20, eval_set_loss = 2.319475541054058\n",
      "i=30, eval_set_loss = 2.2702009991208403\n",
      "i=40, eval_set_loss = 2.2339152296934723\n",
      "i=50, eval_set_loss = 2.2065567688889627\n",
      "i=60, eval_set_loss = 2.185969446633898\n",
      "i=70, eval_set_loss = 2.1702602101751087\n",
      "i=80, eval_set_loss = 2.1581142465537058\n",
      "i=90, eval_set_loss = 2.1486342782947156\n",
      "i=100, eval_set_loss = 2.140865323881568\n",
      "i=110, eval_set_loss = 2.1349144605804455\n",
      "i=120, eval_set_loss = 2.130791743842892\n",
      "i=130, eval_set_loss = 2.1274578942173683\n",
      "i=140, eval_set_loss = 2.1248442745056892\n",
      "i=150, eval_set_loss = 2.1221656297459495\n",
      "i=160, eval_set_loss = 2.120266339837323\n",
      "i=170, eval_set_loss = 2.1187621300707953\n",
      "i=180, eval_set_loss = 2.1178482174243793\n",
      "i=190, eval_set_loss = 2.1166274936295797\n",
      "i=200, eval_set_loss = 2.115834527014455\n",
      "i=210, eval_set_loss = 2.115427609623311\n",
      "i=220, eval_set_loss = 2.114671155270056\n",
      "i=230, eval_set_loss = 2.1143825619074605\n",
      "i=240, eval_set_loss = 2.1143022724726817\n",
      "i=250, eval_set_loss = 2.1138787704608357\n",
      "i=260, eval_set_loss = 2.1137245659320913\n",
      "i=270, eval_set_loss = 2.113297949465522\n",
      "i=280, eval_set_loss = 2.113334098244585\n",
      "Stopping early: curr_loss of 2.113334098244585\n",
      "                                        exceeds compare_loss of 2.113297949465522\n",
      "Singleton weight = 0.7\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.3863687649886733\n",
      "i=20, eval_set_loss = 2.316929918740325\n",
      "i=30, eval_set_loss = 2.267606919674118\n",
      "i=40, eval_set_loss = 2.2315322882527058\n",
      "i=50, eval_set_loss = 2.2044283813053203\n",
      "i=60, eval_set_loss = 2.1842027052542745\n",
      "i=70, eval_set_loss = 2.1687355432221986\n",
      "i=80, eval_set_loss = 2.156564958457841\n",
      "i=90, eval_set_loss = 2.1471994840377957\n",
      "i=100, eval_set_loss = 2.139955049553668\n",
      "i=110, eval_set_loss = 2.1342603127515782\n",
      "i=120, eval_set_loss = 2.1302714230397983\n",
      "i=130, eval_set_loss = 2.126825208053412\n",
      "i=140, eval_set_loss = 2.1243065651489004\n",
      "i=150, eval_set_loss = 2.1221000748456595\n",
      "i=160, eval_set_loss = 2.1205207418743486\n",
      "i=170, eval_set_loss = 2.1194204907416174\n",
      "i=180, eval_set_loss = 2.118393866017296\n",
      "i=190, eval_set_loss = 2.1172918698152072\n",
      "i=200, eval_set_loss = 2.11671838079919\n",
      "i=210, eval_set_loss = 2.116198979667499\n",
      "i=220, eval_set_loss = 2.115658363832671\n",
      "i=230, eval_set_loss = 2.115453822914722\n",
      "i=240, eval_set_loss = 2.1153057739423513\n",
      "i=250, eval_set_loss = 2.115258128251406\n",
      "i=260, eval_set_loss = 2.1151333286884006\n",
      "i=270, eval_set_loss = 2.1147140072548645\n",
      "i=280, eval_set_loss = 2.114618262244707\n",
      "i=290, eval_set_loss = 2.11460802146491\n",
      "i=300, eval_set_loss = 2.114645375805931\n",
      "Stopping early: curr_loss of 2.114645375805931\n",
      "                                        exceeds compare_loss of 2.11460802146491\n",
      "Singleton weight = 0.8\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.3840285130848327\n",
      "i=20, eval_set_loss = 2.3145725731369042\n",
      "i=30, eval_set_loss = 2.265225932268668\n",
      "i=40, eval_set_loss = 2.229067318167219\n",
      "i=50, eval_set_loss = 2.202042757378091\n",
      "i=60, eval_set_loss = 2.1822232492324014\n",
      "i=70, eval_set_loss = 2.1672858614489514\n",
      "i=80, eval_set_loss = 2.155335258099736\n",
      "i=90, eval_set_loss = 2.146220376455751\n",
      "i=100, eval_set_loss = 2.139189561007124\n",
      "i=110, eval_set_loss = 2.1337243730429556\n",
      "i=120, eval_set_loss = 2.1296001656529984\n",
      "i=130, eval_set_loss = 2.126661187938881\n",
      "i=140, eval_set_loss = 2.1241766252823733\n",
      "i=150, eval_set_loss = 2.121869131316716\n",
      "i=160, eval_set_loss = 2.120139886489653\n",
      "i=170, eval_set_loss = 2.1187653910686586\n",
      "i=180, eval_set_loss = 2.1178872613238067\n",
      "i=190, eval_set_loss = 2.117070700014285\n",
      "i=200, eval_set_loss = 2.1164380422469837\n",
      "i=210, eval_set_loss = 2.1160015677728348\n",
      "i=220, eval_set_loss = 2.115638591977564\n",
      "i=230, eval_set_loss = 2.1154161108907883\n",
      "i=240, eval_set_loss = 2.115133546153978\n",
      "i=250, eval_set_loss = 2.114939416168946\n",
      "i=260, eval_set_loss = 2.1148997905189733\n",
      "i=270, eval_set_loss = 2.1145153320819765\n",
      "i=280, eval_set_loss = 2.114701823041099\n",
      "Stopping early: curr_loss of 2.114701823041099\n",
      "                                        exceeds compare_loss of 2.1145153320819765\n",
      "Singleton weight = 0.9\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n",
      "i=10, eval_set_loss = 2.3815499444877872\n",
      "i=20, eval_set_loss = 2.3110152415613614\n",
      "i=30, eval_set_loss = 2.262272369714084\n",
      "i=40, eval_set_loss = 2.2263213768639525\n",
      "i=50, eval_set_loss = 2.1999736638338696\n",
      "i=60, eval_set_loss = 2.179988030415926\n",
      "i=70, eval_set_loss = 2.1648499535614243\n",
      "i=80, eval_set_loss = 2.1533689836054326\n",
      "i=90, eval_set_loss = 2.144597919039134\n",
      "i=100, eval_set_loss = 2.137944423631467\n",
      "i=110, eval_set_loss = 2.132422091573696\n",
      "i=120, eval_set_loss = 2.128417471287337\n",
      "i=130, eval_set_loss = 2.125235660350211\n",
      "i=140, eval_set_loss = 2.122875522996652\n",
      "i=150, eval_set_loss = 2.1211167734611895\n",
      "i=160, eval_set_loss = 2.1197905927316496\n",
      "i=170, eval_set_loss = 2.119061305237426\n",
      "i=180, eval_set_loss = 2.1181355979262664\n",
      "i=190, eval_set_loss = 2.117301315219415\n",
      "i=200, eval_set_loss = 2.1164164996625936\n",
      "i=210, eval_set_loss = 2.1158543576169935\n",
      "i=220, eval_set_loss = 2.115485656306048\n",
      "i=230, eval_set_loss = 2.1154358601468624\n",
      "i=240, eval_set_loss = 2.1153505635263263\n",
      "i=250, eval_set_loss = 2.115441425377021\n",
      "Stopping early: curr_loss of 2.115441425377021\n",
      "                                        exceeds compare_loss of 2.1153505635263263\n",
      "Singleton weight = 1.0\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.485210349363101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_6434/1669956703.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=10, eval_set_loss = 2.3781416628562555\n",
      "i=20, eval_set_loss = 2.306965504682684\n",
      "i=30, eval_set_loss = 2.2584051948503534\n",
      "i=40, eval_set_loss = 2.222696126964833\n",
      "i=50, eval_set_loss = 2.196257430204142\n",
      "i=60, eval_set_loss = 2.1771697133382157\n",
      "i=70, eval_set_loss = 2.1628559930872098\n",
      "i=80, eval_set_loss = 2.1520868292767203\n",
      "i=90, eval_set_loss = 2.1436971712108184\n",
      "i=100, eval_set_loss = 2.13727942507619\n",
      "i=110, eval_set_loss = 2.1321423378420468\n",
      "i=120, eval_set_loss = 2.128210376359964\n",
      "i=130, eval_set_loss = 2.1255618871894693\n",
      "i=140, eval_set_loss = 2.1234381075042847\n",
      "i=150, eval_set_loss = 2.121556646654289\n",
      "i=160, eval_set_loss = 2.1202116676690186\n",
      "i=170, eval_set_loss = 2.119747076251416\n",
      "i=180, eval_set_loss = 2.1190226322449837\n",
      "i=190, eval_set_loss = 2.1184348037872476\n",
      "i=200, eval_set_loss = 2.117814183236862\n",
      "i=210, eval_set_loss = 2.1171705211246348\n",
      "i=220, eval_set_loss = 2.116892613273235\n",
      "i=230, eval_set_loss = 2.1168565628501756\n",
      "i=240, eval_set_loss = 2.116804470781914\n",
      "i=250, eval_set_loss = 2.116671800834989\n",
      "i=260, eval_set_loss = 2.1168356323201953\n",
      "Stopping early: curr_loss of 2.1168356323201953\n",
      "                                        exceeds compare_loss of 2.116671800834989\n",
      "Singleton weight = 0.0\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.4103460089759094\n",
      "i=20, eval_set_loss = 2.3499993720089116\n",
      "i=30, eval_set_loss = 2.3028709083905365\n",
      "i=40, eval_set_loss = 2.2660112522088434\n",
      "i=50, eval_set_loss = 2.2367164692286594\n",
      "i=60, eval_set_loss = 2.2139501316131955\n",
      "i=70, eval_set_loss = 2.195991894876277\n",
      "i=80, eval_set_loss = 2.181530916193626\n",
      "i=90, eval_set_loss = 2.1696652929373585\n",
      "i=100, eval_set_loss = 2.160564949962288\n",
      "i=110, eval_set_loss = 2.152872859862821\n",
      "i=120, eval_set_loss = 2.1464561684504546\n",
      "i=130, eval_set_loss = 2.1413372629607768\n",
      "i=140, eval_set_loss = 2.1368445193496903\n",
      "i=150, eval_set_loss = 2.133069873865174\n",
      "i=160, eval_set_loss = 2.130029583698808\n",
      "i=170, eval_set_loss = 2.1272369365032966\n",
      "i=180, eval_set_loss = 2.12499543377549\n",
      "i=190, eval_set_loss = 2.12295678564584\n",
      "i=200, eval_set_loss = 2.121142557566078\n",
      "i=210, eval_set_loss = 2.119551562606394\n",
      "i=220, eval_set_loss = 2.1181545191242903\n",
      "i=230, eval_set_loss = 2.116848171402829\n",
      "i=240, eval_set_loss = 2.1157402776723147\n",
      "i=250, eval_set_loss = 2.1147241536266805\n",
      "i=260, eval_set_loss = 2.1137938298193393\n",
      "i=270, eval_set_loss = 2.113060765117686\n",
      "i=280, eval_set_loss = 2.1125027121148183\n",
      "i=290, eval_set_loss = 2.1119731103358537\n",
      "i=300, eval_set_loss = 2.1113993409668983\n",
      "i=310, eval_set_loss = 2.1108778085203843\n",
      "i=320, eval_set_loss = 2.110342286394135\n",
      "i=330, eval_set_loss = 2.109849223795685\n",
      "i=340, eval_set_loss = 2.109499008969104\n",
      "i=350, eval_set_loss = 2.1091710635674725\n",
      "i=360, eval_set_loss = 2.1088441880342534\n",
      "i=370, eval_set_loss = 2.1086469326545383\n",
      "i=380, eval_set_loss = 2.10844463080564\n",
      "i=390, eval_set_loss = 2.1083151746391318\n",
      "i=400, eval_set_loss = 2.1082198393173757\n",
      "i=410, eval_set_loss = 2.1079530585641484\n",
      "i=420, eval_set_loss = 2.1078646603463924\n",
      "i=430, eval_set_loss = 2.107928986683939\n",
      "Stopping early: curr_loss of 2.107928986683939\n",
      "                                        exceeds compare_loss of 2.1078646603463924\n",
      "Singleton weight = 0.1\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.391771877765516\n",
      "i=20, eval_set_loss = 2.323038803062553\n",
      "i=30, eval_set_loss = 2.272854735090059\n",
      "i=40, eval_set_loss = 2.235504248181459\n",
      "i=50, eval_set_loss = 2.207182773635207\n",
      "i=60, eval_set_loss = 2.185782629143742\n",
      "i=70, eval_set_loss = 2.1696802420404873\n",
      "i=80, eval_set_loss = 2.156826014603515\n",
      "i=90, eval_set_loss = 2.1466961142082783\n",
      "i=100, eval_set_loss = 2.1387977057268523\n",
      "i=110, eval_set_loss = 2.132627308369867\n",
      "i=120, eval_set_loss = 2.1273055330200665\n",
      "i=130, eval_set_loss = 2.1233762361845883\n",
      "i=140, eval_set_loss = 2.1198220922998927\n",
      "i=150, eval_set_loss = 2.117014391200637\n",
      "i=160, eval_set_loss = 2.1148190740248096\n",
      "i=170, eval_set_loss = 2.1131062335223967\n",
      "i=180, eval_set_loss = 2.111924257721302\n",
      "i=190, eval_set_loss = 2.1106829816705495\n",
      "i=200, eval_set_loss = 2.1097956743738373\n",
      "i=210, eval_set_loss = 2.109056544786816\n",
      "i=220, eval_set_loss = 2.1083477205582977\n",
      "i=230, eval_set_loss = 2.1076557115113013\n",
      "i=240, eval_set_loss = 2.1070738278672847\n",
      "i=250, eval_set_loss = 2.106568401677273\n",
      "i=260, eval_set_loss = 2.1064218886562793\n",
      "i=270, eval_set_loss = 2.1062959429510175\n",
      "i=280, eval_set_loss = 2.1060678346841506\n",
      "i=290, eval_set_loss = 2.1061034076064367\n",
      "Stopping early: curr_loss of 2.1061034076064367\n",
      "                                        exceeds compare_loss of 2.1060678346841506\n",
      "Singleton weight = 0.2\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.3907467981777852\n",
      "i=20, eval_set_loss = 2.321654370601837\n",
      "i=30, eval_set_loss = 2.271416367619549\n",
      "i=40, eval_set_loss = 2.234024370871219\n",
      "i=50, eval_set_loss = 2.205979908777226\n",
      "i=60, eval_set_loss = 2.184473944928804\n",
      "i=70, eval_set_loss = 2.1682900245312804\n",
      "i=80, eval_set_loss = 2.1552224305669587\n",
      "i=90, eval_set_loss = 2.1456674265103635\n",
      "i=100, eval_set_loss = 2.138343006927889\n",
      "i=110, eval_set_loss = 2.131943105633754\n",
      "i=120, eval_set_loss = 2.1270062981174727\n",
      "i=130, eval_set_loss = 2.123711125983303\n",
      "i=140, eval_set_loss = 2.1204351825836705\n",
      "i=150, eval_set_loss = 2.118043908299014\n",
      "i=160, eval_set_loss = 2.1160259351252764\n",
      "i=170, eval_set_loss = 2.1141448456848737\n",
      "i=180, eval_set_loss = 2.1129913137062686\n",
      "i=190, eval_set_loss = 2.1115410903907255\n",
      "i=200, eval_set_loss = 2.110545733237295\n",
      "i=210, eval_set_loss = 2.1099961153501665\n",
      "i=220, eval_set_loss = 2.1095853502968924\n",
      "i=230, eval_set_loss = 2.1090274505007875\n",
      "i=240, eval_set_loss = 2.1085080359169797\n",
      "i=250, eval_set_loss = 2.1078954619581336\n",
      "i=260, eval_set_loss = 2.107580226219753\n",
      "i=270, eval_set_loss = 2.1074323989147308\n",
      "i=280, eval_set_loss = 2.1074500799311235\n",
      "Stopping early: curr_loss of 2.1074500799311235\n",
      "                                        exceeds compare_loss of 2.1074323989147308\n",
      "Singleton weight = 0.3\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.3896050946680267\n",
      "i=20, eval_set_loss = 2.3201020158266568\n",
      "i=30, eval_set_loss = 2.2697846333446976\n",
      "i=40, eval_set_loss = 2.232463501149102\n",
      "i=50, eval_set_loss = 2.20449391220013\n",
      "i=60, eval_set_loss = 2.1833551751915494\n",
      "i=70, eval_set_loss = 2.167216561517802\n",
      "i=80, eval_set_loss = 2.1542611294350427\n",
      "i=90, eval_set_loss = 2.14461318383536\n",
      "i=100, eval_set_loss = 2.1372520121551397\n",
      "i=110, eval_set_loss = 2.1313824816380254\n",
      "i=120, eval_set_loss = 2.1265321357220355\n",
      "i=130, eval_set_loss = 2.1229508012078444\n",
      "i=140, eval_set_loss = 2.119696143752487\n",
      "i=150, eval_set_loss = 2.1172754124423876\n",
      "i=160, eval_set_loss = 2.1152144671612203\n",
      "i=170, eval_set_loss = 2.113492077878653\n",
      "i=180, eval_set_loss = 2.112486152175509\n",
      "i=190, eval_set_loss = 2.111311790961886\n",
      "i=200, eval_set_loss = 2.110366332748752\n",
      "i=210, eval_set_loss = 2.109796089033219\n",
      "i=220, eval_set_loss = 2.109262644572869\n",
      "i=230, eval_set_loss = 2.1082974222519564\n",
      "i=240, eval_set_loss = 2.1077793322566474\n",
      "i=250, eval_set_loss = 2.107238060723724\n",
      "i=260, eval_set_loss = 2.107097628293922\n",
      "i=270, eval_set_loss = 2.1069704735033783\n",
      "i=280, eval_set_loss = 2.106935824907185\n",
      "i=290, eval_set_loss = 2.106904092710098\n",
      "i=300, eval_set_loss = 2.10694388234017\n",
      "Stopping early: curr_loss of 2.10694388234017\n",
      "                                        exceeds compare_loss of 2.106904092710098\n",
      "Singleton weight = 0.4\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.3887310875446923\n",
      "i=20, eval_set_loss = 2.3187851998583224\n",
      "i=30, eval_set_loss = 2.268125750609808\n",
      "i=40, eval_set_loss = 2.2313859025295706\n",
      "i=50, eval_set_loss = 2.203849557628604\n",
      "i=60, eval_set_loss = 2.18256036558813\n",
      "i=70, eval_set_loss = 2.1662764127598493\n",
      "i=80, eval_set_loss = 2.1536033535247685\n",
      "i=90, eval_set_loss = 2.1439941389435138\n",
      "i=100, eval_set_loss = 2.1366833296620222\n",
      "i=110, eval_set_loss = 2.1309502055586593\n",
      "i=120, eval_set_loss = 2.1259802737195788\n",
      "i=130, eval_set_loss = 2.1222705441095946\n",
      "i=140, eval_set_loss = 2.118803930502887\n",
      "i=150, eval_set_loss = 2.1162199253369627\n",
      "i=160, eval_set_loss = 2.114488032541844\n",
      "i=170, eval_set_loss = 2.1129594919407975\n",
      "i=180, eval_set_loss = 2.1118262995679764\n",
      "i=190, eval_set_loss = 2.1106775106694498\n",
      "i=200, eval_set_loss = 2.1098600127933618\n",
      "i=210, eval_set_loss = 2.1093049583292514\n",
      "i=220, eval_set_loss = 2.1089729987574954\n",
      "i=230, eval_set_loss = 2.1083581457148233\n",
      "i=240, eval_set_loss = 2.1079334655490416\n",
      "i=250, eval_set_loss = 2.10744830755995\n",
      "i=260, eval_set_loss = 2.10730087146687\n",
      "i=270, eval_set_loss = 2.107393245260915\n",
      "Stopping early: curr_loss of 2.107393245260915\n",
      "                                        exceeds compare_loss of 2.10730087146687\n",
      "Singleton weight = 0.5\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.387256508355881\n",
      "i=20, eval_set_loss = 2.3168269834108375\n",
      "i=30, eval_set_loss = 2.2665318074790384\n",
      "i=40, eval_set_loss = 2.2295586300170855\n",
      "i=50, eval_set_loss = 2.202204394773235\n",
      "i=60, eval_set_loss = 2.1812733134020936\n",
      "i=70, eval_set_loss = 2.165153333632883\n",
      "i=80, eval_set_loss = 2.152824036645196\n",
      "i=90, eval_set_loss = 2.143528897161582\n",
      "i=100, eval_set_loss = 2.1362661606957314\n",
      "i=110, eval_set_loss = 2.130494095099013\n",
      "i=120, eval_set_loss = 2.1257545257335235\n",
      "i=130, eval_set_loss = 2.1222218522933107\n",
      "i=140, eval_set_loss = 2.1190292242401707\n",
      "i=150, eval_set_loss = 2.1170013571126773\n",
      "i=160, eval_set_loss = 2.115010722329608\n",
      "i=170, eval_set_loss = 2.1132910580987962\n",
      "i=180, eval_set_loss = 2.1123617715518233\n",
      "i=190, eval_set_loss = 2.111305618171735\n",
      "i=200, eval_set_loss = 2.110828193787891\n",
      "i=210, eval_set_loss = 2.1100378842180514\n",
      "i=220, eval_set_loss = 2.1097053412749074\n",
      "i=230, eval_set_loss = 2.1090491226955432\n",
      "i=240, eval_set_loss = 2.1084238418831585\n",
      "i=250, eval_set_loss = 2.107919637950546\n",
      "i=260, eval_set_loss = 2.107962005995399\n",
      "Stopping early: curr_loss of 2.107962005995399\n",
      "                                        exceeds compare_loss of 2.107919637950546\n",
      "Singleton weight = 0.6\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.3854543120629366\n",
      "i=20, eval_set_loss = 2.3145862646908086\n",
      "i=30, eval_set_loss = 2.264185090250957\n",
      "i=40, eval_set_loss = 2.2273919281875902\n",
      "i=50, eval_set_loss = 2.2002188274594374\n",
      "i=60, eval_set_loss = 2.1798754963721754\n",
      "i=70, eval_set_loss = 2.163920786350723\n",
      "i=80, eval_set_loss = 2.151930675791726\n",
      "i=90, eval_set_loss = 2.1426685072402396\n",
      "i=100, eval_set_loss = 2.1357277850674783\n",
      "i=110, eval_set_loss = 2.130335454839524\n",
      "i=120, eval_set_loss = 2.125267508125961\n",
      "i=130, eval_set_loss = 2.1221073562219206\n",
      "i=140, eval_set_loss = 2.119125167966749\n",
      "i=150, eval_set_loss = 2.116995061183176\n",
      "i=160, eval_set_loss = 2.1151133152764254\n",
      "i=170, eval_set_loss = 2.1134745245432534\n",
      "i=180, eval_set_loss = 2.1127623683935286\n",
      "i=190, eval_set_loss = 2.111644074176406\n",
      "i=200, eval_set_loss = 2.110640737593782\n",
      "i=210, eval_set_loss = 2.1100843024175227\n",
      "i=220, eval_set_loss = 2.1096844271593787\n",
      "i=230, eval_set_loss = 2.109259436766803\n",
      "i=240, eval_set_loss = 2.1087959705927837\n",
      "i=250, eval_set_loss = 2.1081509261284124\n",
      "i=260, eval_set_loss = 2.108115802865153\n",
      "i=270, eval_set_loss = 2.107918649531781\n",
      "i=280, eval_set_loss = 2.107940437359268\n",
      "Stopping early: curr_loss of 2.107940437359268\n",
      "                                        exceeds compare_loss of 2.107918649531781\n",
      "Singleton weight = 0.7\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.383539030249071\n",
      "i=20, eval_set_loss = 2.3119089271700193\n",
      "i=30, eval_set_loss = 2.2612950526896816\n",
      "i=40, eval_set_loss = 2.224839558556497\n",
      "i=50, eval_set_loss = 2.1976775587609585\n",
      "i=60, eval_set_loss = 2.1769162545523746\n",
      "i=70, eval_set_loss = 2.1616166490430992\n",
      "i=80, eval_set_loss = 2.1497411635026618\n",
      "i=90, eval_set_loss = 2.1408423209029266\n",
      "i=100, eval_set_loss = 2.1337788227498677\n",
      "i=110, eval_set_loss = 2.1283142887923874\n",
      "i=120, eval_set_loss = 2.1238384745063428\n",
      "i=130, eval_set_loss = 2.1204265212228037\n",
      "i=140, eval_set_loss = 2.117624436406377\n",
      "i=150, eval_set_loss = 2.1158141201408602\n",
      "i=160, eval_set_loss = 2.1143229292789525\n",
      "i=170, eval_set_loss = 2.1126665013341106\n",
      "i=180, eval_set_loss = 2.111755798600196\n",
      "i=190, eval_set_loss = 2.110547383172631\n",
      "i=200, eval_set_loss = 2.1096506767684504\n",
      "i=210, eval_set_loss = 2.109414802266505\n",
      "i=220, eval_set_loss = 2.108849640655173\n",
      "i=230, eval_set_loss = 2.1085532268622105\n",
      "i=240, eval_set_loss = 2.1082506709826263\n",
      "i=250, eval_set_loss = 2.1080605020445202\n",
      "i=260, eval_set_loss = 2.10828891473928\n",
      "Stopping early: curr_loss of 2.10828891473928\n",
      "                                        exceeds compare_loss of 2.1080605020445202\n",
      "Singleton weight = 0.8\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.380939248454606\n",
      "i=20, eval_set_loss = 2.3097892662234663\n",
      "i=30, eval_set_loss = 2.2592418119860813\n",
      "i=40, eval_set_loss = 2.22277737966684\n",
      "i=50, eval_set_loss = 2.195377493747077\n",
      "i=60, eval_set_loss = 2.1754841683101462\n",
      "i=70, eval_set_loss = 2.1601296959078997\n",
      "i=80, eval_set_loss = 2.1479950984046607\n",
      "i=90, eval_set_loss = 2.1386009335541756\n",
      "i=100, eval_set_loss = 2.1317376817406966\n",
      "i=110, eval_set_loss = 2.126535257518293\n",
      "i=120, eval_set_loss = 2.122213655449457\n",
      "i=130, eval_set_loss = 2.119359908472107\n",
      "i=140, eval_set_loss = 2.116900502825336\n",
      "i=150, eval_set_loss = 2.114714488331511\n",
      "i=160, eval_set_loss = 2.1129933995070007\n",
      "i=170, eval_set_loss = 2.1115283969621603\n",
      "i=180, eval_set_loss = 2.1107184469825238\n",
      "i=190, eval_set_loss = 2.109732861108133\n",
      "i=200, eval_set_loss = 2.1091942600555833\n",
      "i=210, eval_set_loss = 2.10900576549505\n",
      "i=220, eval_set_loss = 2.108764519466607\n",
      "i=230, eval_set_loss = 2.108023340541821\n",
      "i=240, eval_set_loss = 2.107764476535227\n",
      "i=250, eval_set_loss = 2.1075135780542245\n",
      "i=260, eval_set_loss = 2.107414921625599\n",
      "i=270, eval_set_loss = 2.107421797008428\n",
      "Stopping early: curr_loss of 2.107421797008428\n",
      "                                        exceeds compare_loss of 2.107414921625599\n",
      "Singleton weight = 0.9\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n",
      "i=10, eval_set_loss = 2.3780834021211152\n",
      "i=20, eval_set_loss = 2.306387032918864\n",
      "i=30, eval_set_loss = 2.256053268825284\n",
      "i=40, eval_set_loss = 2.2205043409415115\n",
      "i=50, eval_set_loss = 2.1938255319175837\n",
      "i=60, eval_set_loss = 2.173745458719908\n",
      "i=70, eval_set_loss = 2.158883735654252\n",
      "i=80, eval_set_loss = 2.147448332985863\n",
      "i=90, eval_set_loss = 2.1389189562866675\n",
      "i=100, eval_set_loss = 2.1325578135453123\n",
      "i=110, eval_set_loss = 2.127482396631172\n",
      "i=120, eval_set_loss = 2.123514221445213\n",
      "i=130, eval_set_loss = 2.120393291762394\n",
      "i=140, eval_set_loss = 2.1178398853524487\n",
      "i=150, eval_set_loss = 2.1159225559338815\n",
      "i=160, eval_set_loss = 2.114616326231011\n",
      "i=170, eval_set_loss = 2.1132190173727974\n",
      "i=180, eval_set_loss = 2.1126159294919677\n",
      "i=190, eval_set_loss = 2.112141020675786\n",
      "i=200, eval_set_loss = 2.1115632721189206\n",
      "i=210, eval_set_loss = 2.1109992854259243\n",
      "i=220, eval_set_loss = 2.110839767787628\n",
      "i=230, eval_set_loss = 2.110416706981453\n",
      "i=240, eval_set_loss = 2.1099672042220416\n",
      "i=250, eval_set_loss = 2.109775649445704\n",
      "i=260, eval_set_loss = 2.1099841993173998\n",
      "Stopping early: curr_loss of 2.1099841993173998\n",
      "                                        exceeds compare_loss of 2.109775649445704\n",
      "Singleton weight = 1.0\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.4853017662347763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_6434/1669956703.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=10, eval_set_loss = 2.3747990484973105\n",
      "i=20, eval_set_loss = 2.3024321378745727\n",
      "i=30, eval_set_loss = 2.2520723295916905\n",
      "i=40, eval_set_loss = 2.216950112464602\n",
      "i=50, eval_set_loss = 2.1909315887030067\n",
      "i=60, eval_set_loss = 2.172131885297348\n",
      "i=70, eval_set_loss = 2.1569914022650427\n",
      "i=80, eval_set_loss = 2.1455875420137285\n",
      "i=90, eval_set_loss = 2.1372153884361773\n",
      "i=100, eval_set_loss = 2.1314030016942573\n",
      "i=110, eval_set_loss = 2.126574104948428\n",
      "i=120, eval_set_loss = 2.1227062818907414\n",
      "i=130, eval_set_loss = 2.120018943344937\n",
      "i=140, eval_set_loss = 2.1175112287480906\n",
      "i=150, eval_set_loss = 2.115764938507603\n",
      "i=160, eval_set_loss = 2.114087584076755\n",
      "i=170, eval_set_loss = 2.1127957458780613\n",
      "i=180, eval_set_loss = 2.112011146019843\n",
      "i=190, eval_set_loss = 2.1115142489152925\n",
      "i=200, eval_set_loss = 2.110814400826439\n",
      "i=210, eval_set_loss = 2.1107406046141026\n",
      "i=220, eval_set_loss = 2.1107652263337053\n",
      "Stopping early: curr_loss of 2.1107652263337053\n",
      "                                        exceeds compare_loss of 2.1107406046141026\n"
     ]
    }
   ],
   "source": [
    "train_size = 5000\n",
    "valid_size = 5000\n",
    "test_size = 100000\n",
    "num_trials= 5\n",
    "sw_vec = np.arange(0,11)/10\n",
    "\n",
    "ll_mat = np.zeros((num_trials, len(sw_vec)))\n",
    "acc_mat = np.zeros((num_trials, len(sw_vec)))\n",
    "\n",
    "\n",
    "for tr in range(num_trials):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X,y,test_size=test_size, random_state=tr)\n",
    "    X_train_rem, X_valid, y_train_rem, y_valid = train_test_split(X_train_val, y_train_val, test_size=valid_size, random_state=tr)\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(X_train_rem, y_train_rem, train_size=train_size, random_state=tr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i,sw in enumerate(sw_vec):\n",
    "        print('Singleton weight = {}'.format(sw))\n",
    "        print('trial_number = {}'.format(tr))\n",
    "        ts = {}\n",
    "        ts['partition_type'] = 'fixed'\n",
    "        ts['partition_list'] = [ [[0,1,2],[3,4,5],[6,7,8],[9,10,11]],\n",
    "                                 [[1,2,3],[4,5,6],[7,8,9],[10,11,0]],\n",
    "                                 [[2,3,4],[5,6,7],[8,9,10],[11,0,1]] ]\n",
    "        ts['singleton_weight'] = sw\n",
    "        rem = (1-sw)/3\n",
    "        ts['partition_weight_vec'] = [rem, rem, rem]\n",
    "        stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n",
    "        stb_tmp.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)\n",
    "        preds_tmp = stb_tmp.predict_proba(X_test)\n",
    "        ll = log_loss(y_test, preds_tmp)\n",
    "        hard_preds = np.argmax(preds_tmp,axis=1)\n",
    "        acc = accuracy_score(y_test,hard_preds)\n",
    "        ll_mat[tr,i] = ll\n",
    "        acc_mat[tr,i] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13ae35430>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ll_vec = np.mean(ll_mat, axis=0)\n",
    "plt.plot(sw_vec, ll_vec, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13b18d280>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_vec = np.mean(acc_mat, axis=0)\n",
    "plt.plot(sw_vec, acc_vec, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
